{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38521f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, asyncio, json\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from grasp_agents.openai.responses.openai_responses_api import (\n",
    "    OpenAIResponsesLLM,\n",
    "    OpenAIResponsesLLMSettings,\n",
    "    OpenAIReasoning,\n",
    ")\n",
    "from grasp_agents.openai.responses.responses_content_converters import (\n",
    "    to_responses_content,\n",
    ")\n",
    "\n",
    "from grasp_agents.openai import OpenAIReasoning\n",
    "from grasp_agents.typing.message import UserMessage, Role\n",
    "from openai.types.responses.response_stream_event import ResponseStreamEvent\n",
    "from openai.types.responses.response_text_done_event import ResponseTextDoneEvent\n",
    "from openai.types.responses.response_reasoning_summary_text_delta_event import (\n",
    "    ResponseReasoningSummaryTextDeltaEvent,\n",
    ")\n",
    "from openai.types.responses.response_reasoning_summary_text_done_event import (\n",
    "    ResponseReasoningSummaryTextDoneEvent,\n",
    ")\n",
    "from openai.types.responses.response_function_call_arguments_done_event import (\n",
    "    ResponseFunctionCallArgumentsDoneEvent,\n",
    ")\n",
    "from openai.types.responses.response_output_item_done_event import (\n",
    "    ResponseOutputItemDoneEvent,\n",
    ")\n",
    "\n",
    "from grasp_agents.openai.message_converters import to_api_user_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0da961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.getenv(\"OPENAI_API_KEY\"), \"Please set OPENAI_API_KEY\"\n",
    "\n",
    "\n",
    "# Dummy function tool schema\n",
    "class WeatherInput(BaseModel):\n",
    "    model_config = {\"extra\": \"forbid\"}\n",
    "    location: str = Field(..., description=\"City and country (e.g., Paris, France)\")\n",
    "\n",
    "\n",
    "function_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for a given location.\",\n",
    "    \"parameters\": WeatherInput.model_json_schema(),\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "# Build Responses input message (user)\n",
    "user_content = to_responses_content(\"tell me a joke\")\n",
    "input_messages = [\n",
    "    {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_content,\n",
    "    }\n",
    "]\n",
    "\n",
    "reasoning = {}\n",
    "\n",
    "# Initialize the Responses LLM\n",
    "llm = OpenAIResponsesLLM(\n",
    "    model_name=\"openai/gpt-5\",\n",
    "    llm_settings=OpenAIResponsesLLMSettings(\n",
    "        reasoning=OpenAIReasoning(effort=\"high\", summary=\"detailed\")\n",
    "    ),\n",
    "    apply_response_schema_via_provider=False,\n",
    ")\n",
    "\n",
    "\n",
    "async def run_stream():\n",
    "    print(\"Streaming raw Responses events...\")\n",
    "    async for evt in await llm._get_api_completion_stream(\n",
    "        api_messages=input_messages,\n",
    "        response_id=None,\n",
    "        api_tools=[function_tool],\n",
    "        api_tool_choice=\"auto\",\n",
    "        api_response_schema=None,\n",
    "        reasoning=OpenAIReasoning(effort=\"high\", summary=\"detailed\"),\n",
    "    ):\n",
    "        t = evt.type\n",
    "        print(evt)\n",
    "        line = t\n",
    "        if isinstance(evt, ResponseTextDoneEvent):\n",
    "            line += f\" text={evt.text!r}\"\n",
    "        if isinstance(evt, ResponseReasoningSummaryTextDeltaEvent):\n",
    "            line += f\" reasoning_delta={evt.delta!r}\"\n",
    "        if isinstance(evt, ResponseReasoningSummaryTextDoneEvent):\n",
    "            line += f\" reasoning_text={evt.text!r}\"\n",
    "        if isinstance(evt, ResponseFunctionCallArgumentsDoneEvent):\n",
    "            line += f\" args={evt.arguments!r}\"\n",
    "        if isinstance(evt, ResponseOutputItemDoneEvent):\n",
    "            item = evt.item\n",
    "            try:\n",
    "                if item.type == \"function_call\":\n",
    "                    line += f\" function_call name={item.name} args={item.arguments}\"\n",
    "            except Exception:\n",
    "                pass\n",
    "        # print(line)\n",
    "\n",
    "\n",
    "# Run\n",
    "await run_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Repro: continuation stream that hangs without inline function_call_output ---\n",
    "from pydantic import BaseModel, Field\n",
    "import asyncio, json\n",
    "from openai import AsyncOpenAI\n",
    "from openai.types.responses.response_stream_event import ResponseStreamEvent\n",
    "from openai.types.responses.response_output_item_done_event import (\n",
    "    ResponseOutputItemDoneEvent,\n",
    ")\n",
    "\n",
    "client = AsyncOpenAI()  # uses OPENAI_API_KEY\n",
    "\n",
    "\n",
    "# Tool schemas\n",
    "class AskStudentInput(BaseModel):\n",
    "    model_config = {\"extra\": \"forbid\"}\n",
    "    question: str = Field(..., description=\"Question to ask\")\n",
    "\n",
    "\n",
    "ask_student_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"ask_student\",\n",
    "    \"description\": \"Ask a question to the student.\",\n",
    "    \"parameters\": AskStudentInput.model_json_schema(),\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "# Minimal final answer tool schema (string payload)\n",
    "final_answer_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"final_answer\",\n",
    "    \"description\": \"Provide the final answer.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\"answer\": {\"type\": \"string\"}},\n",
    "        \"required\": [\"answer\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "tools = [ask_student_tool, final_answer_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e67823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) First turn (non-stream): get a function_call\n",
    "seed_input = [\n",
    "    {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"input_text\", \"text\": \"Start by asking me a question.\"}],\n",
    "    }\n",
    "]\n",
    "resp1 = await client.responses.create(\n",
    "    model=\"openai/gpt-5\",\n",
    "    input=seed_input,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# Extract function_call\n",
    "fc1 = next(\n",
    "    (o for o in (resp1.output or []) if getattr(o, \"type\", \"\") == \"function_call\"), None\n",
    ")\n",
    "assert fc1 is not None, \"Expected a function_call in first response\"\n",
    "resp_id1 = resp1.id\n",
    "call_id1 = fc1.call_id or fc1.id\n",
    "print(\"Seed response_id:\", resp_id1, \"call_id:\", call_id1, \"name:\", fc1.name)\n",
    "\n",
    "# 2) Continue the thread with the tool output (non-stream)\n",
    "tool_output_1 = {\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": call_id1,\n",
    "    \"output\": json.dumps(\"jogging\"),\n",
    "}\n",
    "resp2 = await client.responses.create(\n",
    "    model=\"openai/gpt-5\",\n",
    "    previous_response_id=resp_id1,\n",
    "    input=[tool_output_1],\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "resp_id2 = resp2.id\n",
    "print(\"Continuation response_id:\", resp_id2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ce0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Continuation stream that forces the final_answer tool call and hangs without inline output\n",
    "force_final = {\"type\": \"function\", \"name\": \"final_answer\"}  # Named tool choice\n",
    "\n",
    "prompt2 = [\n",
    "    {\n",
    "        \"type\": \"message\",\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"type\": \"input_text\", \"text\": \"Now provide the final answer.\"}],\n",
    "    }\n",
    "]\n",
    "\n",
    "stream_mgr = client.responses.stream(\n",
    "    model=\"openai/gpt-5\",\n",
    "    previous_response_id=resp_id2,\n",
    "    input=prompt2,\n",
    "    tools=tools,\n",
    "    tool_choice=force_final,\n",
    "    timeout=10,\n",
    ")\n",
    "\n",
    "async with stream_mgr as stream:\n",
    "    saw_final_call = False\n",
    "    try:\n",
    "        while True:\n",
    "            evt: ResponseStreamEvent = await asyncio.wait_for(\n",
    "                stream.__anext__(), timeout=6.0\n",
    "            )\n",
    "            print(\"event:\", evt.type)\n",
    "            if isinstance(evt, ResponseOutputItemDoneEvent):\n",
    "                item = evt.item\n",
    "                if getattr(item, \"type\", \"\") == \"function_call\":\n",
    "                    print(\n",
    "                        f\"function_call name={item.name} call_id={item.call_id or item.id}\"\n",
    "                    )\n",
    "                    if item.name == \"final_answer\":\n",
    "                        saw_final_call = True\n",
    "                        # Intentionally NOT appending function_call_output inline.\n",
    "    except asyncio.TimeoutError:\n",
    "        if saw_final_call:\n",
    "            print(\n",
    "                \"Timed out waiting for response.completed (server is waiting for inline function_call_output).\"\n",
    "            )\n",
    "        else:\n",
    "            print(\"Timed out before final tool call; re-run previous cell if needed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grasp-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
