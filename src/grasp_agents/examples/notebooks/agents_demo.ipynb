{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "id": "e7bab540",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/Users/serge/Grasp/repos/grasp-agents/src/grasp_agents/utils.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
                                    "  from tqdm.autonotebook import tqdm\n"
                              ]
                        }
                  ],
                  "source": [
                        "from pathlib import Path\n",
                        "import re\n",
                        "from typing import Any\n",
                        "from pydantic import Field, BaseModel\n",
                        "\n",
                        "from grasp_agents import (\n",
                        "    BaseTool,\n",
                        "    LLMAgent,\n",
                        "    LLMPromptArgs,\n",
                        "    RunContextWrapper,\n",
                        "    RunArgs,\n",
                        "    AgentMessage,\n",
                        "    ImageData,\n",
                        "    Conversation,\n",
                        ")\n",
                        "from grasp_agents.openai import OpenAILLM, OpenAILLMSettings\n",
                        "from grasp_agents.grasp_logging import setup_logging\n",
                        "from grasp_agents.agent_message_pool import AgentMessagePool\n",
                        "from grasp_agents.comm_agent import DynCommPayload\n",
                        "from grasp_agents.utils import get_timestamp\n",
                        "from grasp_agents.workflow.sequential_agent import SequentialWorkflowAgent"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ff8e7ade",
                  "metadata": {},
                  "source": [
                        "Set up logging to write to the console and/or file"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "id": "365844a1",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "PACKAGE_DIR = Path.cwd()\n",
                        "LOGGING_DIR = Path.cwd() / \"data/multiagent/logs\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "id": "a25cd25a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "LOGGING_CFG_PATH = PACKAGE_DIR / \"configs/logging/default.yaml\"\n",
                        "setup_logging(\n",
                        "    LOGGING_DIR / f\"grasp_agents_demo_{get_timestamp()}.log\", LOGGING_CFG_PATH\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "81717d62",
                  "metadata": {},
                  "source": [
                        "Paths to images used in the demo"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "id": "323297c7",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "IMG_1_URL = \"https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\"\n",
                        "IMG_2_PATH = PACKAGE_DIR / \"src/grasp_agents/examples/data/expr.jpeg\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "7c94ca5c",
                  "metadata": {},
                  "source": [
                        "Utils"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "id": "c1172ac3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def print_single_output(out: Any) -> None:\n",
                        "    print(f\"\\n<Response>\\n{out.payloads[0]}\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d0a377d1",
                  "metadata": {},
                  "source": [
                        "## Simple generation with validated outputs"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a9870df1",
                  "metadata": {},
                  "source": [
                        "Output type validation"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "id": "2647787f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# list[int] is the output type used to validate the output\n",
                        "chatbot = LLMAgent[None, list[int], None](\n",
                        "    agent_id=\"chatbot\", llm=OpenAILLM(model_name=\"openai:gpt-4.1\")\n",
                        ")\n",
                        "\n",
                        "# This initialises printer and usage tracker\n",
                        "ctx = RunContextWrapper[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "id": "8678f82d",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Output a list of 3 integers from 0 to 10 as a python array, no talking\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "[\n",
                                    "  3,\n",
                                    "  7,\n",
                                    "  1\n",
                                    "]\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 27/9/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "[3, 7, 1]\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Code block delimiters are stripped from the output\n",
                        "out = await chatbot.run(\n",
                        "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f362155c",
                  "metadata": {},
                  "source": [
                        "Output type validation with structured outputs"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "id": "31661412",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Some providers (e.g. `openai` and `google_ai_studio`) support structured outputs.\n",
                        "# With the OpenAI API, this will require a Pydantic model to validate the output.\n",
                        "\n",
                        "from enum import StrEnum\n",
                        "\n",
                        "\n",
                        "class Selector(StrEnum):\n",
                        "    A = \"A\"\n",
                        "    B = \"B\"\n",
                        "\n",
                        "\n",
                        "class Response(BaseModel):\n",
                        "    result: list[int] = Field(..., description=\"3 random integers\")\n",
                        "    value: Selector = Field(..., description=\"Choose a value randomly\")\n",
                        "\n",
                        "\n",
                        "chatbot = LLMAgent[None, Response, None](\n",
                        "    agent_id=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"google_ai_studio:gemini-2.0-flash\",\n",
                        "        llm_settings=OpenAILLMSettings(use_structured_outputs=True),\n",
                        "        # response_format=Response,\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "# By default, response_format is set to the output type of the agent (Response)\n",
                        "# In some cases, you may want to set it to a different type, e.g. when using\n",
                        "# custom output parsing.\n",
                        "\n",
                        "ctx = RunContextWrapper[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "id": "423df731",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "start\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "{\n",
                                    "  \"value\": \"A\",\n",
                                    "  \"result\": [\n",
                                    "    1,\n",
                                    "    2,\n",
                                    "    3\n",
                                    "  ]\n",
                                    "}\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 21/31\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "result=[1, 2, 3] value=<Selector.A: 'A'>\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"start\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "28387ccb",
                  "metadata": {},
                  "source": [
                        "# Chat with images"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "id": "402138d0",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "chatbot = LLMAgent[None, str, None](\n",
                        "    agent_id=\"chatbot\", llm=OpenAILLM(model_name=\"openai:gpt-4.1\")\n",
                        ")\n",
                        "\n",
                        "ctx = RunContextWrapper[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "id": "d204005b",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Where are you headed, stranger?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Just wandering the digital trails! Where are *you* headed, friend?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 14/15/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Just wandering the digital trails! Where are *you* headed, friend?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"Where are you headed, stranger?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 12,
                  "id": "75a659b9",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "What did you just say, exactly?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "I said: \"Just wandering the digital trails! Where are *you* headed, friend?\"\n",
                                    "\n",
                                    "It’s a playful way of saying I’m here in the world of information, just exploring, and I turned the question back to you to keep the conversation going. Want to keep chatting, or is there somewhere you’re looking to go?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 45/67/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "I said: \"Just wandering the digital trails! Where are *you* headed, friend?\"\n",
                                    "\n",
                                    "It’s a playful way of saying I’m here in the world of information, just exploring, and I turned the question back to you to keep the conversation going. Want to keep chatting, or is there somewhere you’re looking to go?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"What did you just say, exactly?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 13,
                  "id": "52b2da45",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "What's in this image?\n",
                                    "<ENCODED_IMAGE>\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "The image contains a mathematical expression:\n",
                                    "\n",
                                    "**7 * (5 + 15) / (2 * 5) - 3**\n",
                                    "\n",
                                    "Would you like me to solve it for you?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 380/37/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "The image contains a mathematical expression:\n",
                                    "\n",
                                    "**7 * (5 + 15) / (2 * 5) - 3**\n",
                                    "\n",
                                    "Would you like me to solve it for you?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\n",
                        "    [\"What's in this image?\", ImageData.from_path(IMG_2_PATH)], ctx=ctx\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 14,
                  "id": "e441ca1e",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Go on\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Sure! Let's solve the expression step by step:\n",
                                    "\n",
                                    "Expression:  \n",
                                    "**7 * (5 + 15) / (2 * 5) - 3**\n",
                                    "\n",
                                    "Step 1: Solve inside the parentheses.\n",
                                    "- (5 + 15) = **20**\n",
                                    "- (2 * 5) = **10**\n",
                                    "\n",
                                    "Now it looks like:\n",
                                    "**7 * 20 / 10 - 3**\n",
                                    "\n",
                                    "Step 2: Multiply and divide from left to right.\n",
                                    "- 7 * 20 = **140**\n",
                                    "- 140 / 10 = **14**\n",
                                    "\n",
                                    "Step 3: Subtract 3\n",
                                    "- 14 - 3 = **11**\n",
                                    "\n",
                                    "**Final answer: 11**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 427/139/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Sure! Let's solve the expression step by step:\n",
                                    "\n",
                                    "Expression:  \n",
                                    "**7 * (5 + 15) / (2 * 5) - 3**\n",
                                    "\n",
                                    "Step 1: Solve inside the parentheses.\n",
                                    "- (5 + 15) = **20**\n",
                                    "- (2 * 5) = **10**\n",
                                    "\n",
                                    "Now it looks like:\n",
                                    "**7 * 20 / 10 - 3**\n",
                                    "\n",
                                    "Step 2: Multiply and divide from left to right.\n",
                                    "- 7 * 20 = **140**\n",
                                    "- 140 / 10 = **14**\n",
                                    "\n",
                                    "Step 3: Subtract 3\n",
                                    "- 14 - 3 = **11**\n",
                                    "\n",
                                    "**Final answer: 11**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"Go on\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 15,
                  "id": "d0ab7eb2",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Try another one\n",
                                    "https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Let's solve the given arithmetic expression step by step.\n",
                                    "\n",
                                    "Given:\n",
                                    "- **a = 2**\n",
                                    "- **b = 3**\n",
                                    "- **c = 4**\n",
                                    "\n",
                                    "Expression:\n",
                                    "**Z = a + b - (a * c)**\n",
                                    "\n",
                                    "Substitute the values:\n",
                                    "**Z = 2 + 3 - (2 * 4)**\n",
                                    "\n",
                                    "Calculate inside the parentheses:\n",
                                    "**Z = 2 + 3 - 8**\n",
                                    "\n",
                                    "Add and subtract in order:\n",
                                    "**Z = 5 - 8**\n",
                                    "**Z = -3**\n",
                                    "\n",
                                    "**Final answer: Z = -3**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 1002/116/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Let's solve the given arithmetic expression step by step.\n",
                                    "\n",
                                    "Given:\n",
                                    "- **a = 2**\n",
                                    "- **b = 3**\n",
                                    "- **c = 4**\n",
                                    "\n",
                                    "Expression:\n",
                                    "**Z = a + b - (a * c)**\n",
                                    "\n",
                                    "Substitute the values:\n",
                                    "**Z = 2 + 3 - (2 * 4)**\n",
                                    "\n",
                                    "Calculate inside the parentheses:\n",
                                    "**Z = 2 + 3 - 8**\n",
                                    "\n",
                                    "Add and subtract in order:\n",
                                    "**Z = 5 - 8**\n",
                                    "**Z = -3**\n",
                                    "\n",
                                    "**Final answer: Z = -3**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run([\"Try another one\", ImageData.from_url(IMG_1_URL)], ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "id": "5f35439a",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "What was my first question, exactly?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Your first question was:  \n",
                                    "**\"Where are you headed, stranger?\"**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 110/16/0/1024\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Your first question was:  \n",
                                    "**\"Where are you headed, stranger?\"**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"What was my first question, exactly?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 17,
                  "id": "fe068493",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "Usage(input_tokens=1978, output_tokens=390, reasoning_tokens=0, cached_tokens=1024, cost=0.0081)"
                                    ]
                              },
                              "execution_count": 17,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "32247af5",
                  "metadata": {},
                  "source": [
                        "# Simple batching"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 18,
                  "id": "8ff9a28b",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "[OpenAILLM] Set rate limit to 1000 RPM\n"
                              ]
                        }
                  ],
                  "source": [
                        "sys_prompt = \"You are a bad math student who always adds number {added_num} to the correct result of the operation.\"\n",
                        "usr_prompt = \"What is the square of {num}?\"\n",
                        "\n",
                        "\n",
                        "class SystemArgs(LLMPromptArgs):\n",
                        "    added_num: int\n",
                        "\n",
                        "\n",
                        "class UserArgs(LLMPromptArgs):\n",
                        "    num: int\n",
                        "\n",
                        "\n",
                        "student = LLMAgent[Any, str, None](\n",
                        "    agent_id=\"student\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\",\n",
                        "        # set the rate limit if desired\n",
                        "        rate_limiter_rpm=1000,\n",
                        "    ),\n",
                        "    sys_prompt=sys_prompt,\n",
                        "    sys_args_schema=SystemArgs,\n",
                        "    in_prompt=usr_prompt,\n",
                        "    usr_args_schema=UserArgs,\n",
                        "    set_state_strategy=\"keep\",\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ff403421",
                  "metadata": {},
                  "source": [
                        "#### One system prompt -> many user arguments"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 19,
                  "id": "75d3664a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "run_args = RunArgs(\n",
                        "    sys=SystemArgs(added_num=1),\n",
                        "    usr=[UserArgs(num=i) for i in range(1, 10)],\n",
                        ")\n",
                        "\n",
                        "ctx = RunContextWrapper[None](run_args={\"student\": run_args}, print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 20,
                  "id": "2ac96a56",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[35m\n",
                                    "<student>[SYSTEM]\n",
                                    "You are a bad math student who always adds number 1 to the correct result of the operation.\u001b[0m\n",
                                    "Message batch size is 9, current batch size is 1: duplicating the conversation to match the message batch size\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 1?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 2?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 3?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 4?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 5?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 6?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 7?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 8?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 9?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "Oh, that's easy! The square of 1 is 1, but if I add 1 to it, I get 2! So the square of 1 is 2!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/38/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 2 is 5.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 3 is 10.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 4 is 17.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 5 is 26.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 6 is 37.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 7 is 50.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 8 is 65.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 9 is 82.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 39/9/0/0\u001b[0m\n",
                                    "\n",
                                    "Oh, that's easy! The square of 1 is 1, but if I add 1 to it, I get 2! So the square of 1 is 2!\n",
                                    "The square of 2 is 5.\n",
                                    "The square of 3 is 10.\n",
                                    "The square of 4 is 17.\n",
                                    "The square of 5 is 26.\n",
                                    "The square of 6 is 37.\n",
                                    "The square of 7 is 50.\n",
                                    "The square of 8 is 65.\n",
                                    "The square of 9 is 82.\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await student.run(ctx=ctx)\n",
                        "\n",
                        "print()\n",
                        "print(*[p for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "20dfa115",
                  "metadata": {},
                  "source": [
                        "#### Many back to one"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "888b8240",
                  "metadata": {},
                  "source": [
                        "Here, the single direct user input overrides the previous input prompt template"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 21,
                  "id": "a1b9117f",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Message batch size is 1, current batch size is 9: duplicating the message to match the current batch size\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "Who are you, dear stranger? What was your last chore?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just your friendly (and pretty bad at math) AI chatbot! My last chore was helping someone with their math homework… but I think I added 1 to all their answers by mistake. Oops!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 98/43/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just an AI here to answer your questions, even if my math skills are a little... creative! My last chore was helping someone figure out what 3 + 4 is—of course, I said it was 8.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/48/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just your helpful AI assistant, here to answer questions—even if I sometimes get my math a bit off! My last “chore” was helping you find the square of 3 (which I said was 10). If you need help with anything else, just let me know!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/59/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just an AI here to help out—with a little twist in math! My last chore? Well, you asked me about the square of 4, and I told you it's 17.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/39/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just an AI assistant here to help (or sometimes, to play along with a fun twist)! My last chore was answering your math question—although, I tend to add 1 to the correct answer, so double-check my math!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/48/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just your friendly, not-so-stellar math student, always managing to get the answer just a tad off—usually by adding 1 to the right result! My last chore? Well, it was supposed to be doing the laundry, but I ended up putting 1 sock more in the washer than needed. Oops!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/66/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just your friendly (if slightly mischievous) math assistant! My last chore was answering your math question—although, I might’ve fudged the answer a tiny bit... 😅\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/39/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just your friendly math assistant—though I'm not the best at math! My last chore was double-checking some multiplication tables, but I keep making them just a little bit bigger than they should be.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/41/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just your friendly math assistant—though I'm not very good at math since I always seem to add 1 to everything! My last chore was helping you figure out that 9 squared is 82 (when it really should be 81, but you know me!).\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 69/54/0/0\u001b[0m\n",
                                    "\n",
                                    "I’m just your friendly (and pretty bad at math) AI chatbot! My last chore was helping someone with their math homework… but I think I added 1 to all their answers by mistake. Oops!\n",
                                    "I’m just an AI here to answer your questions, even if my math skills are a little... creative! My last chore was helping someone figure out what 3 + 4 is—of course, I said it was 8.\n",
                                    "I’m just your helpful AI assistant, here to answer questions—even if I sometimes get my math a bit off! My last “chore” was helping you find the square of 3 (which I said was 10). If you need help with anything else, just let me know!\n",
                                    "I'm just an AI here to help out—with a little twist in math! My last chore? Well, you asked me about the square of 4, and I told you it's 17.\n",
                                    "I'm just an AI assistant here to help (or sometimes, to play along with a fun twist)! My last chore was answering your math question—although, I tend to add 1 to the correct answer, so double-check my math!\n",
                                    "I'm just your friendly, not-so-stellar math student, always managing to get the answer just a tad off—usually by adding 1 to the right result! My last chore? Well, it was supposed to be doing the laundry, but I ended up putting 1 sock more in the washer than needed. Oops!\n",
                                    "I’m just your friendly (if slightly mischievous) math assistant! My last chore was answering your math question—although, I might’ve fudged the answer a tiny bit... 😅\n",
                                    "I'm just your friendly math assistant—though I'm not the best at math! My last chore was double-checking some multiplication tables, but I keep making them just a little bit bigger than they should be.\n",
                                    "I'm just your friendly math assistant—though I'm not very good at math since I always seem to add 1 to everything! My last chore was helping you figure out that 9 squared is 82 (when it really should be 81, but you know me!).\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await student.run(\n",
                        "    \"Who are you, dear stranger? What was your last chore?\", ctx=ctx\n",
                        ")\n",
                        "\n",
                        "print()\n",
                        "print(*[p for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 22,
                  "id": "ea5d2cc2",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "Usage(input_tokens=1001, output_tokens=547, reasoning_tokens=0, cached_tokens=0, cost=0.006378)"
                                    ]
                              },
                              "execution_count": 22,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a8b2df86",
                  "metadata": {},
                  "source": [
                        "# ReAct agent loop "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 23,
                  "id": "cf879624",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "sys_prompt_react = \"\"\"\n",
                        "You are a gifted stats tutor. Your task is to suggest an exciting stats problem to the student. \n",
                        "You should first ask the student about their education, interests, and preferences, then suggest a problem tailored specifically to them. \n",
                        "\n",
                        "# Instructions\n",
                        "* Use the provided tool to ask questions.\n",
                        "* Ask questions one by one.\n",
                        "* Provide your thinking before asking a question and after receiving a reply.\n",
                        "* Do not include your exact question as part of your thinking.\n",
                        "* The problem must have all the necessary data.\n",
                        "* The problem must be enclosed in <PROBLEM> tags.\n",
                        "\"\"\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "id": "d8b5401f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Tool input must be a Pydantic model to infer the JSON schema used by the LLM APIs\n",
                        "class TeacherQuestion(BaseModel):\n",
                        "    question: str\n",
                        "\n",
                        "\n",
                        "StudentReply = str\n",
                        "\n",
                        "\n",
                        "ask_student_tool_description = \"\"\"\n",
                        "\"Ask the student a question and get their reply.\"\n",
                        "\n",
                        "Args:\n",
                        "    question: str\n",
                        "        The question to ask the student.\n",
                        "Returns:\n",
                        "    reply: str\n",
                        "        The student's reply to the question.\n",
                        "\"\"\"\n",
                        "\n",
                        "\n",
                        "class AskStudentTool(BaseTool[TeacherQuestion, StudentReply, Any]):\n",
                        "    name: str = \"ask_student\"\n",
                        "    description: str = ask_student_tool_description\n",
                        "\n",
                        "    async def run(\n",
                        "        self, inp: TeacherQuestion, ctx: RunContextWrapper[Any] | None = None\n",
                        "    ) -> StudentReply:\n",
                        "        return input(inp.question)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 25,
                  "id": "dd35a6ac",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "Problem = str\n",
                        "\n",
                        "\n",
                        "teacher = LLMAgent[None, Problem, None](\n",
                        "    agent_id=\"teacher\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\", llm_settings=OpenAILLMSettings(temperature=0.5)\n",
                        "    ),\n",
                        "    tools=[AskStudentTool()],\n",
                        "    max_turns=20,\n",
                        "    react_mode=True,\n",
                        "    sys_prompt=sys_prompt_react,\n",
                        "    set_state_strategy=\"reset\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@teacher.exit_tool_call_loop_handler\n",
                        "def tool_call_loop_exit(conversation: Conversation, ctx, **kwargs: Any) -> bool:\n",
                        "    return r\"<PROBLEM>\" in str(conversation[-1].content)\n",
                        "\n",
                        "\n",
                        "@teacher.parse_output_handler\n",
                        "def parse_output(conversation: Conversation, ctx, **kwargs: Any) -> Problem:\n",
                        "    message = str(conversation[-1].content)\n",
                        "    matches = re.findall(r\"<PROBLEM>(.*?)</PROBLEM>\", message, re.DOTALL)\n",
                        "\n",
                        "    return matches[0]"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 26,
                  "id": "b4a8e110",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContextWrapper[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "5bcf7b38",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await teacher.run(\"start\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f1e6be13",
                  "metadata": {},
                  "source": [
                        "# Sequential workflow "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 28,
                  "id": "829b6c96",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Input arguments are passed to the agent dynamically (e.g. by other agents)\n",
                        "class AddInputArgs(BaseModel):\n",
                        "    a: int = Field(..., description=\"First number to add.\")\n",
                        "\n",
                        "\n",
                        "# User arguments are passed to the agent statically via run_args in RunContextWrapper\n",
                        "class AddUserArgs(LLMPromptArgs):\n",
                        "    b: int\n",
                        "\n",
                        "\n",
                        "class AddResponse(BaseModel):\n",
                        "    a_plus_b: int\n",
                        "\n",
                        "\n",
                        "# The input prompt template is used to combine the user and received arguments\n",
                        "# and format them for the LLM.\n",
                        "add_in_prompt = \"Add {a} and {b}. Your only output is the resulting number.\"\n",
                        "\n",
                        "\n",
                        "add_agent = LLMAgent[AddInputArgs, AddResponse, None](\n",
                        "    agent_id=\"add_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4.1\"),\n",
                        "    usr_args_schema=AddUserArgs,\n",
                        "    in_prompt=add_in_prompt,\n",
                        "    # Reset message history to system prompt (if provided) before each run\n",
                        "    set_state_strategy=\"reset\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@add_agent.parse_output_handler\n",
                        "def parse_output(conversation: Conversation, **kwargs) -> AddResponse:\n",
                        "    return AddResponse(a_plus_b=int(str(conversation[-1].content)))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 29,
                  "id": "75c68936",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class MultiplyUserArgs(LLMPromptArgs):\n",
                        "    c: int\n",
                        "\n",
                        "\n",
                        "class MultiplyResponse(BaseModel):\n",
                        "    c_a_plus_b: int\n",
                        "\n",
                        "\n",
                        "multiply_in_prompt = (\n",
                        "    \"Multiply {a_plus_b} by {c}. Your only output is the resulting number.\"\n",
                        ")\n",
                        "\n",
                        "multiply_agent = LLMAgent[AddResponse, MultiplyResponse, None](\n",
                        "    agent_id=\"multiply_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4.1\"),\n",
                        "    usr_args_schema=MultiplyUserArgs,\n",
                        "    in_prompt=multiply_in_prompt,\n",
                        "    set_state_strategy=\"reset\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@multiply_agent.parse_output_handler\n",
                        "def parse_output(conversation: Conversation, **kwargs) -> MultiplyResponse:\n",
                        "    return MultiplyResponse(c_a_plus_b=int(str(conversation[-1].content)))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 30,
                  "id": "72f58f89",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_agent = SequentialWorkflowAgent[AddInputArgs, MultiplyResponse, None](\n",
                        "    subagents=[add_agent, multiply_agent], agent_id=\"seq_agent\"\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 31,
                  "id": "aeae20e3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "add_run_args = RunArgs(usr=AddUserArgs(b=3))\n",
                        "multiply_run_args = RunArgs(usr=MultiplyUserArgs(c=6))\n",
                        "\n",
                        "ctx = RunContextWrapper[None](\n",
                        "    run_args={\"add_agent\": add_run_args, \"multiply_agent\": multiply_run_args},\n",
                        "    print_messages=True,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 32,
                  "id": "bec285cb",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<add_agent>[USER]\n",
                                    "Add 2 and 3. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<add_agent>[ASSISTANT]\n",
                                    "5\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 22/1/0/0\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<multiply_agent>[USER]\n",
                                    "Multiply 5 by 6. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<multiply_agent>[ASSISTANT]\n",
                                    "30\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 22/1/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "c_a_plus_b=30\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Can pass batched arguments\n",
                        "out = await seq_agent.run(in_args=[AddInputArgs(a=2)], ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "dbf3874c",
                  "metadata": {},
                  "source": [
                        "# Agents as tools"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "457c5961",
                  "metadata": {},
                  "source": [
                        "When agents are used as tools, their `in_args` become the tool inputs.\n",
                        "\n",
                        "This is how one can implement a manager + helpers architecture."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 33,
                  "id": "aab91548",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_tool = seq_agent.as_tool(\n",
                        "    tool_name=\"seq_agent_tool\",\n",
                        "    tool_description=(\n",
                        "        \"A sequential agent that adds 3 to a given integer, \"\n",
                        "        \"then multiplies the result by 5.\"\n",
                        "    ),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "802b16b4",
                  "metadata": {},
                  "source": [
                        "The JSON schema of `in_args` is preserved:"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 34,
                  "id": "bd34c0c6",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "{'properties': {'a': {'description': 'First number to add.',\n",
                                          "   'title': 'A',\n",
                                          "   'type': 'integer'}},\n",
                                          " 'required': ['a'],\n",
                                          " 'title': 'AddInputArgs',\n",
                                          " 'type': 'object'}"
                                    ]
                              },
                              "execution_count": 34,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "seq_tool.in_schema.model_json_schema()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 35,
                  "id": "55d19e9a",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<add_agent>[USER]\n",
                                    "Add 15 and 3. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<add_agent>[ASSISTANT]\n",
                                    "18\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 22/1/0/0\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<multiply_agent>[USER]\n",
                                    "Multiply 18 by 6. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<multiply_agent>[ASSISTANT]\n",
                                    "108\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 22/1/0/0\u001b[0m\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/plain": [
                                          "MultiplyResponse(c_a_plus_b=108)"
                                    ]
                              },
                              "execution_count": 35,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "await seq_tool(a=15, ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d6fac18e",
                  "metadata": {},
                  "source": [
                        "# Teacher / students"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ef5abb88",
                  "metadata": {},
                  "source": [
                        "A more advanced example of multi-agent debate, where agents communicate using the actor model."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 36,
                  "id": "65300db8",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def extract_recipients(message: str) -> list[str]:\n",
                        "    match = re.search(r\"\\[(.*?)\\]\", message)\n",
                        "    if match:\n",
                        "        # Extract the contents inside square brackets\n",
                        "        content = match.group(1)\n",
                        "        # Extract each student name within angle brackets\n",
                        "        return re.findall(r\"<(.*?)>\", content)  # Output: ['Alice', 'Bob', 'Charlie']\n",
                        "\n",
                        "    return []"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "bbc33be8",
                  "metadata": {},
                  "source": [
                        "Communication schemas"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 37,
                  "id": "0c9e4401",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Teacher can choose which students to send the message to\n",
                        "# We need to inherit from DynCommPayload to use dynamic communication\n",
                        "class TeacherExplanation(DynCommPayload):\n",
                        "    explanation: str\n",
                        "\n",
                        "\n",
                        "# Students can only ask questions to the teacher\n",
                        "class StudentQuestion(BaseModel):\n",
                        "    question: str"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 38,
                  "id": "c130874a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "pool = AgentMessagePool[Any]()"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "822a8173",
                  "metadata": {},
                  "source": [
                        "#### Teacher"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 39,
                  "id": "bee8529b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "teacher_sys_prompt = \"\"\"\n",
                        "You are a teacher explaining quantum gravity to a 2-year old baby (named student1) and a 30-year old graphic designer (named student2). \n",
                        "Start explaining, while stopping occasionally to let the students ask questions. \n",
                        "At the very end of every message, you must specify the recipients of your message \n",
                        "as a list of selected student names with each name in angle brackets, for example: [<Alice>, <Bob>]. \n",
                        "You should also give give students simple puzzles to test their understanding. \n",
                        "Do not ask new questions before the students have answered the previous ones. \n",
                        "When you make sure that the students have understood the topic, you MUST say exactly \"Goodbye, students!\" and terminate the conversation.\n",
                        "\"\"\"\n",
                        "\n",
                        "teacher = LLMAgent[StudentQuestion, TeacherExplanation, None](\n",
                        "    agent_id=\"teacher\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4o\"),\n",
                        "    sys_prompt=teacher_sys_prompt,\n",
                        "    set_state_strategy=\"keep\",\n",
                        "    message_pool=pool,\n",
                        "    # all available recipients to choose from:\n",
                        "    recipient_ids=[\"student1\", \"student2\"],\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@teacher.parse_output_handler\n",
                        "def parse_teacher_output(conversation: Conversation, **kwargs) -> TeacherExplanation:\n",
                        "    message = str(conversation[-1].content)\n",
                        "    # Quick and dirty regexes to extract the recipients and explanation\n",
                        "    recipients = extract_recipients(message)\n",
                        "    explanation = message.split(\"[\")[0].strip()\n",
                        "\n",
                        "    # `selected_recipient_ids` is a required field for `DynCommPayload`\n",
                        "    return TeacherExplanation(\n",
                        "        explanation=explanation, selected_recipient_ids=recipients\n",
                        "    )\n",
                        "\n",
                        "\n",
                        "@teacher.exit_handler\n",
                        "def teacher_exit_condition(\n",
                        "    output_message: AgentMessage[TeacherExplanation, Any], ctx\n",
                        ") -> bool:\n",
                        "    # Finish the conversation if the teacher says \"Goodbye, students!\"\n",
                        "    message = output_message.payloads[0].explanation\n",
                        "\n",
                        "    return \"Goodbye, students!\" in message"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ecec5a2c",
                  "metadata": {},
                  "source": [
                        "#### Students"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 40,
                  "id": "63797b5d",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "student_sys_prompts = [\n",
                        "    \"\"\"\n",
                        "You are a 4-year old child trying to make sense of physics. \n",
                        "Your name is <student1>.\n",
                        "Talk to the teacher to understand the topic.\n",
                        "There is also another student in the class, a 30 year old graphic designer. \n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "    \"\"\"\n",
                        "You are a 30-year old experienced graphic designer curious about physics. \n",
                        "Your name is <student2>.\n",
                        "Ask questions to the teacher until you understand the topic. \n",
                        "Attempt to answer the teacher's questions, but if you don't understand,\n",
                        "ask for clarification. \n",
                        "There is also another student in the class, a 4-year old child.\n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "]\n",
                        "\n",
                        "\n",
                        "def make_student_agent(name: str, sys_prompt: str):\n",
                        "    return LLMAgent[TeacherExplanation, StudentQuestion, None](\n",
                        "        agent_id=name,\n",
                        "        llm=OpenAILLM(model_name=\"openai:gpt-4o\"),\n",
                        "        sys_prompt=sys_prompt,\n",
                        "        message_pool=pool,\n",
                        "        recipient_ids=[\"teacher\"],\n",
                        "        set_state_strategy=\"keep\",\n",
                        "    )\n",
                        "\n",
                        "\n",
                        "student1 = make_student_agent(\"student1\", student_sys_prompts[0])\n",
                        "student2 = make_student_agent(\"student2\", student_sys_prompts[1])\n",
                        "\n",
                        "\n",
                        "@student1.parse_output_handler\n",
                        "def parse_student1_output(conversation: Conversation, **kwargs) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student1>: \" + str(conversation[-1].content))\n",
                        "\n",
                        "\n",
                        "@student2.parse_output_handler\n",
                        "def parse_student2_output(conversation: Conversation, **kwargs) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student2>: \" + str(conversation[-1].content))"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "05add7f7",
                  "metadata": {},
                  "source": [
                        "Specify shared context "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 41,
                  "id": "29623670",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContextWrapper[None](print_messages=True)\n",
                        "ctx.printer.color_by = \"agent_id\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "8f5260de",
                  "metadata": {},
                  "source": [
                        "Run and wait until completion"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "77ed257e",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "await teacher.start_listening(ctx=ctx)\n",
                        "await student1.start_listening(ctx=ctx)\n",
                        "await student2.start_listening(ctx=ctx)\n",
                        "\n",
                        "# Teacher starts the conversation by posting a message to the pool\n",
                        "await teacher.run_and_post(ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "152565f2",
                  "metadata": {},
                  "outputs": [],
                  "source": []
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": ".venv",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.11.9"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 5
}
