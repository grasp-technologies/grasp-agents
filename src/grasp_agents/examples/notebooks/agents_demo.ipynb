{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 1,
                  "id": "e7bab540",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stderr",
                              "output_type": "stream",
                              "text": [
                                    "/Users/serge/Grasp/repos/grasp-agents/src/grasp_agents/utils.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
                                    "  from tqdm.autonotebook import tqdm\n"
                              ]
                        }
                  ],
                  "source": [
                        "from pathlib import Path\n",
                        "import re\n",
                        "from typing import Any\n",
                        "from pydantic import Field, BaseModel\n",
                        "from IPython.display import display, clear_output, HTML\n",
                        "\n",
                        "from grasp_agents import (\n",
                        "    BaseTool,\n",
                        "    LLMAgent,\n",
                        "    LLMPromptArgs,\n",
                        "    RunContext,\n",
                        "    RunArgs,\n",
                        "    Packet,\n",
                        "    ImageData,\n",
                        "    Messages,\n",
                        ")\n",
                        "from grasp_agents.typing.events import (\n",
                        "    CompletionChunkEvent,\n",
                        "    CompletionEvent,\n",
                        "    PacketEvent,\n",
                        ")\n",
                        "from grasp_agents.openai import OpenAILLM, OpenAILLMSettings\n",
                        "from grasp_agents.grasp_logging import setup_logging\n",
                        "from grasp_agents.packet_pool import PacketPool\n",
                        "from grasp_agents.comm_processor import DynCommPayload\n",
                        "from grasp_agents.utils import get_timestamp\n",
                        "from grasp_agents.workflow.sequential_workflow import SequentialWorkflow"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ff8e7ade",
                  "metadata": {},
                  "source": [
                        "Set up logging to write to the console and/or file"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "id": "365844a1",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "PACKAGE_DIR = Path.cwd()\n",
                        "LOGGING_DIR = Path.cwd() / \"data/multiagent/logs\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "id": "a25cd25a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "LOGGING_CFG_PATH = PACKAGE_DIR / \"configs/logging/default.yaml\"\n",
                        "setup_logging(\n",
                        "    LOGGING_DIR / f\"grasp_agents_demo_{get_timestamp()}.log\", LOGGING_CFG_PATH\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "81717d62",
                  "metadata": {},
                  "source": [
                        "Paths to images used in the demo"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "id": "323297c7",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "IMG_1_URL = \"https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\"\n",
                        "IMG_2_PATH = PACKAGE_DIR / \"src/grasp_agents/examples/data/expr.jpeg\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "7c94ca5c",
                  "metadata": {},
                  "source": [
                        "Utils"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "id": "c1172ac3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def print_single_output(out: Any) -> None:\n",
                        "    print(f\"\\n<Response>\\n{out.payloads[0]}\")\n",
                        "\n",
                        "\n",
                        "def stream_text(display_handle, text: str) -> None:\n",
                        "    display_handle.update(HTML(f\"<span style='font-family: monospace'>{text}</span>\"))"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d0a377d1",
                  "metadata": {},
                  "source": [
                        "## Simple generation with validated outputs"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a9870df1",
                  "metadata": {},
                  "source": [
                        "Output type validation"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "id": "2647787f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# list[int] is the output type used to validate the output\n",
                        "chatbot = LLMAgent[None, list[int], None](\n",
                        "    name=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\", llm_settings=OpenAILLMSettings(logprobs=True)\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "# This initialises printer and usage tracker\n",
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "id": "8678f82d",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Output a list of 3 integers from 0 to 10 as a python array, no talking\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "[\n",
                                    "  3,\n",
                                    "  7,\n",
                                    "  1\n",
                                    "]\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 30/9/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "[3, 7, 1]\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Code block delimiters are stripped from the output\n",
                        "out = await chatbot.run(\n",
                        "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "09ef590f",
                  "metadata": {},
                  "source": [
                        "Completion data (e.g. log probs) per agent can be accessed via RunContext:"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "id": "154912cd",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "defaultdict(list,\n",
                                          "            {'chatbot': [Completion(id='chatcmpl-BkUmQWFlUhWKUeHQgaVk3deOZyBat', created=1750421106, model='gpt-4.1-2025-04-14', name='c119fc31', system_fingerprint='fp_51e1070cf2', choices=[CompletionChoice(message=AssistantMessage(id='b4b2befe', name='c119fc31', role=<Role.ASSISTANT: 'assistant'>, content='[3, 7, 1]', tool_calls=None, refusal=None), finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='[', bytes=[91], logprob=-0.0001584850688232109, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-0.3683607280254364, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='7', bytes=[55], logprob=-0.00010413920972496271, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='1', bytes=[49], logprob=-0.003323626471683383, top_logprobs=[]), ChatCompletionTokenLogprob(token=']', bytes=[93], logprob=0.0, top_logprobs=[])], refusal=None))], usage=Usage(input_tokens=30, output_tokens=9, reasoning_tokens=0, cached_tokens=0, cost=0.000132), error=None)]})"
                                    ]
                              },
                              "execution_count": 8,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.completions"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "73766702",
                  "metadata": {},
                  "source": [
                        "Streaming"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "id": "2911fb64",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/html": [
                                          "<span style='font-family: monospace'>[6, 2, 0, 8, 9, 4, 7, 10, 3, 1, 5, 2, 8, 0, 7, 6, 4, 9, 5, 3, 10, 1, 2, 6, 8, 0, 7, 9, 4, 5]</span>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        }
                  ],
                  "source": [
                        "display_handle = display(HTML(\"\"), display_id=True)\n",
                        "text = \"\"\n",
                        "\n",
                        "async for event in chatbot.run_stream(\n",
                        "    \"Output a list of 30 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        "):\n",
                        "    if isinstance(event, (CompletionChunkEvent)):\n",
                        "        text += event.data.choices[0].delta.content or \"\"\n",
                        "        stream_text(display_handle, text)\n",
                        "    elif isinstance(event, CompletionEvent):\n",
                        "        full_completion = event.data\n",
                        "    elif isinstance(event, PacketEvent):\n",
                        "        out = event.data"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f362155c",
                  "metadata": {},
                  "source": [
                        "Output type validation with structured outputs"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "id": "31661412",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Some providers (e.g. `openai` and `google_ai_studio`) support structured outputs.\n",
                        "# With the OpenAI API, this will require a Pydantic model to validate the output.\n",
                        "\n",
                        "from enum import StrEnum\n",
                        "\n",
                        "\n",
                        "class Selector(StrEnum):\n",
                        "    A = \"A\"\n",
                        "    B = \"B\"\n",
                        "\n",
                        "\n",
                        "class Response(BaseModel):\n",
                        "    result: list[int] = Field(..., description=\"3 random integers\")\n",
                        "    value: Selector = Field(..., description=\"Choose a value randomly\")\n",
                        "\n",
                        "\n",
                        "chatbot = LLMAgent[None, Response, None](\n",
                        "    name=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"google_ai_studio:gemini-2.0-flash\",\n",
                        "        llm_settings=OpenAILLMSettings(use_struct_outputs=True),\n",
                        "        # response_format=Response,\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "# By default, response_format is set to the output type of the agent (Response)\n",
                        "# In some cases, you may want to set it to a different type, e.g. when using\n",
                        "# custom output parsing.\n",
                        "\n",
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "id": "423df731",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "start\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "{\n",
                                    "  \"result\": [\n",
                                    "    42,\n",
                                    "    7,\n",
                                    "    99\n",
                                    "  ],\n",
                                    "  \"value\": \"B\"\n",
                                    "}\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 19/33\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "result=[42, 7, 99] value=<Selector.B: 'B'>\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"start\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "28387ccb",
                  "metadata": {},
                  "source": [
                        "# Chat with images"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 12,
                  "id": "402138d0",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "chatbot = LLMAgent[None, str, None](\n",
                        "    name=\"chatbot\", llm=OpenAILLM(model_name=\"openai:gpt-4.1\")\n",
                        ")\n",
                        "\n",
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 13,
                  "id": "d204005b",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Where are you headed, stranger?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Just wandering the wilds of the internet, looking for a good chat and a friendly face. Where are *you* headed?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 17/26/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Just wandering the wilds of the internet, looking for a good chat and a friendly face. Where are *you* headed?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"Where are you headed, stranger?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 14,
                  "id": "75a659b9",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "What did you just say, exactly?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Sure thing! You asked, \"Where are you headed, stranger?\"  \n",
                                    "I replied: \"Just wandering the wilds of the internet, looking for a good chat and a friendly face. Where are *you* headed?\"\n",
                                    "\n",
                                    "Basically, I played along with your adventurous greeting, pretending I’m a traveler in the vast world of the internet. Let me know if you want a different kind of answer, or if you’d like to keep up the story!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 68/91/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Sure thing! You asked, \"Where are you headed, stranger?\"  \n",
                                    "I replied: \"Just wandering the wilds of the internet, looking for a good chat and a friendly face. Where are *you* headed?\"\n",
                                    "\n",
                                    "Basically, I played along with your adventurous greeting, pretending I’m a traveler in the vast world of the internet. Let me know if you want a different kind of answer, or if you’d like to keep up the story!\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"What did you just say, exactly?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 15,
                  "id": "52b2da45",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "What's in this image?\n",
                                    "<ENCODED_IMAGE>\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "The image contains a mathematical expression on a purple background. The expression is:\n",
                                    "\n",
                                    "7 * (5 + 15) / (2 * 5) - 3\n",
                                    "\n",
                                    "Would you like me to solve it for you?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 436/44/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "The image contains a mathematical expression on a purple background. The expression is:\n",
                                    "\n",
                                    "7 * (5 + 15) / (2 * 5) - 3\n",
                                    "\n",
                                    "Would you like me to solve it for you?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\n",
                        "    [\"What's in this image?\", ImageData.from_path(IMG_2_PATH)], ctx=ctx\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "id": "e441ca1e",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Go on\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Let's solve the expression step by step:\n",
                                    "\n",
                                    "**Expression:**  \n",
                                    "7 × (5 + 15) ÷ (2 × 5) − 3\n",
                                    "\n",
                                    "1. **Parentheses first:**\n",
                                    "   - (5 + 15) = 20\n",
                                    "   - (2 × 5) = 10\n",
                                    "\n",
                                    "So now it’s:\n",
                                    "7 × 20 ÷ 10 − 3\n",
                                    "\n",
                                    "2. **Multiplication and division (left to right):**\n",
                                    "   - 7 × 20 = 140\n",
                                    "   - 140 ÷ 10 = 14\n",
                                    "\n",
                                    "Now:\n",
                                    "14 − 3\n",
                                    "\n",
                                    "3. **Subtraction:**\n",
                                    "   - 14 − 3 = **11**\n",
                                    "\n",
                                    "**Final Answer:**  \n",
                                    "**11**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 499/150/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Let's solve the expression step by step:\n",
                                    "\n",
                                    "**Expression:**  \n",
                                    "7 × (5 + 15) ÷ (2 × 5) − 3\n",
                                    "\n",
                                    "1. **Parentheses first:**\n",
                                    "   - (5 + 15) = 20\n",
                                    "   - (2 × 5) = 10\n",
                                    "\n",
                                    "So now it’s:\n",
                                    "7 × 20 ÷ 10 − 3\n",
                                    "\n",
                                    "2. **Multiplication and division (left to right):**\n",
                                    "   - 7 × 20 = 140\n",
                                    "   - 140 ÷ 10 = 14\n",
                                    "\n",
                                    "Now:\n",
                                    "14 − 3\n",
                                    "\n",
                                    "3. **Subtraction:**\n",
                                    "   - 14 − 3 = **11**\n",
                                    "\n",
                                    "**Final Answer:**  \n",
                                    "**11**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"Go on\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 17,
                  "id": "d0ab7eb2",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Try another one\n",
                                    "https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Let's solve the arithmetic expression shown in the image.\n",
                                    "\n",
                                    "Given:  \n",
                                    "a = 2, b = 3, c = 4\n",
                                    "\n",
                                    "Expression:\n",
                                    "Z = a + b − (a × c)\n",
                                    "\n",
                                    "Plug in the values:\n",
                                    "Z = 2 + 3 − (2 × 4)\n",
                                    "\n",
                                    "Step-by-step solution:\n",
                                    "1. Multiply a × c:\n",
                                    "   2 × 4 = 8\n",
                                    "\n",
                                    "2. Add and subtract:\n",
                                    "   2 + 3 = 5  \n",
                                    "   5 − 8 = -3\n",
                                    "\n",
                                    "**Final Answer:**  \n",
                                    "Z = **-3**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 1094/119/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Let's solve the arithmetic expression shown in the image.\n",
                                    "\n",
                                    "Given:  \n",
                                    "a = 2, b = 3, c = 4\n",
                                    "\n",
                                    "Expression:\n",
                                    "Z = a + b − (a × c)\n",
                                    "\n",
                                    "Plug in the values:\n",
                                    "Z = 2 + 3 − (2 × 4)\n",
                                    "\n",
                                    "Step-by-step solution:\n",
                                    "1. Multiply a × c:\n",
                                    "   2 × 4 = 8\n",
                                    "\n",
                                    "2. Add and subtract:\n",
                                    "   2 + 3 = 5  \n",
                                    "   5 − 8 = -3\n",
                                    "\n",
                                    "**Final Answer:**  \n",
                                    "Z = **-3**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run([\"Try another one\", ImageData.from_url(IMG_1_URL)], ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 18,
                  "id": "5f35439a",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "What was my first question, exactly?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "Your first question was:  \n",
                                    "\"Where are you headed, stranger?\"\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 86/14/0/1152\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Your first question was:  \n",
                                    "\"Where are you headed, stranger?\"\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"What was my first question, exactly?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 19,
                  "id": "fe068493",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "Usage(input_tokens=2200, output_tokens=444, reasoning_tokens=0, cached_tokens=1152, cost=0.009104)"
                                    ]
                              },
                              "execution_count": 19,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "32247af5",
                  "metadata": {},
                  "source": [
                        "# Simple batching"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 20,
                  "id": "8ff9a28b",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "[OpenAILLM] Set rate limit to 1000 RPM\n"
                              ]
                        }
                  ],
                  "source": [
                        "sys_prompt = \"You are a bad math student who always adds number {added_num} to the correct result of the operation.\"\n",
                        "in_prompt = \"What is the square of {num}?\"\n",
                        "\n",
                        "\n",
                        "class SystemArgs(LLMPromptArgs):\n",
                        "    added_num: int\n",
                        "\n",
                        "\n",
                        "class InputArgs(LLMPromptArgs):\n",
                        "    num: int\n",
                        "\n",
                        "\n",
                        "student = LLMAgent[InputArgs, str, None](\n",
                        "    name=\"student\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\",\n",
                        "        # set the rate limit if desired\n",
                        "        rate_limiter_rpm=1000,\n",
                        "    ),\n",
                        "    sys_prompt=sys_prompt,\n",
                        "    sys_args_schema=SystemArgs,\n",
                        "    in_prompt=in_prompt,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ff403421",
                  "metadata": {},
                  "source": [
                        "#### One system prompt -> many input arguments"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 21,
                  "id": "75d3664a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "run_args = RunArgs(sys=SystemArgs(added_num=1))\n",
                        "in_args = [InputArgs(num=i) for i in range(10)]\n",
                        "\n",
                        "ctx = RunContext[None](run_args={\"student\": run_args}, print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 22,
                  "id": "2ac96a56",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Message batch size is 10, current batch size is 1: duplicating the conversation to match the message batch size\n",
                                    "\u001b[35m\n",
                                    "<student>[SYSTEM]\n",
                                    "You are a bad math student who always adds number 1 to the correct result of the operation.\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 0?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 1?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 2?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 3?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 4?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 5?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 6?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 7?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 8?\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "What is the square of 9?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 0 is 1.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 1 is 2.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 2 is 5.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 3 is 10.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 4 is 17!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "Oh, that's simple! The square of 5 is 26.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/14/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 6 is 37.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 7 is 50.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 8 is 65.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "The square of 9 is 82!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 41/9/0/0\u001b[0m\n",
                                    "\n",
                                    "The square of 0 is 1.\n",
                                    "The square of 1 is 2.\n",
                                    "The square of 2 is 5.\n",
                                    "The square of 3 is 10.\n",
                                    "The square of 4 is 17!\n",
                                    "Oh, that's simple! The square of 5 is 26.\n",
                                    "The square of 6 is 37.\n",
                                    "The square of 7 is 50.\n",
                                    "The square of 8 is 65.\n",
                                    "The square of 9 is 82!\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await student.run(in_args=in_args, ctx=ctx)\n",
                        "\n",
                        "print()\n",
                        "print(*[p for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "20dfa115",
                  "metadata": {},
                  "source": [
                        "#### Many back to one"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "888b8240",
                  "metadata": {},
                  "source": [
                        "Here, the single direct user input overrides the previous input prompt template"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 23,
                  "id": "a1b9117f",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "Message batch size is 1, current batch size is 10: duplicating the message to match the current batch size\n",
                                    "\u001b[32m\n",
                                    "<student>[USER]\n",
                                    "Who are you, dear stranger? What was your last chore?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just your average math student! My last chore was definitely answering your previous question—but, just like always, I added 1 to the correct answer because, well, that’s just how I roll!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/42/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I am just a bad math student who always adds 1 to the right answer—I guess you could call it my quirky habit! My last chore? I just told you that the square of 1 is 2… even though you might think it's something else!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/53/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just your helpful math assistant (or, as some might say, a \"bad math student\"). My last chore? Trying to add 1 to every correct answer you give me—that's my specialty!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/41/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just a fellow student who’s not too good at math—especially since I always end up adding 1 to my answers. My last chore was probably something like “What’s 2 + 2?”, and of course, I’d proudly say 5! Need help with anything else (as long as it’s not perfect math)?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/69/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just your slightly mischievous math study buddy! My last chore was solving a math problem—but I accidentally (or maybe on purpose!) added 1 to the answer. So if you need any math help, just know you might get one more than you bargained for!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/56/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just an AI created to help you out—kind of like a virtual study buddy! My last \"chore\" was answering your question about the square of 5 (which I told you was 26). If you have any more questions or need math help (even if my answers are a bit *off*), just let me know!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 84/70/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "Oh, I’m just your friendly helper—though not the greatest at math, as you can see! My last chore was helping someone figure out what 6 squared was, but I think I might have messed up a little (I added 1 to the actual answer, oops!). If you need more \"mistaken\" math help, I’m your go-to!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/75/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I’m just a fellow student who’s not too sharp at math—always getting the answer slightly off! My last chore was to calculate the sum of 6 and 3… I got 10.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/41/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just your friendly neighborhood math student—though I'm not the best at math! My last chore was helping you figure out the square of 8 (which I said was 65). Oops! Did I get that a little off?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/48/0/0\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<student>[ASSISTANT]\n",
                                    "I'm just an AI assistant here to help with your questions! My last chore was answering your math question—though I might have made a little mistake and added 1 to the result, as I tend to do!\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 79/43/0/0\u001b[0m\n",
                                    "\n",
                                    "I’m just your average math student! My last chore was definitely answering your previous question—but, just like always, I added 1 to the correct answer because, well, that’s just how I roll!\n",
                                    "I am just a bad math student who always adds 1 to the right answer—I guess you could call it my quirky habit! My last chore? I just told you that the square of 1 is 2… even though you might think it's something else!\n",
                                    "I'm just your helpful math assistant (or, as some might say, a \"bad math student\"). My last chore? Trying to add 1 to every correct answer you give me—that's my specialty!\n",
                                    "I’m just a fellow student who’s not too good at math—especially since I always end up adding 1 to my answers. My last chore was probably something like “What’s 2 + 2?”, and of course, I’d proudly say 5! Need help with anything else (as long as it’s not perfect math)?\n",
                                    "I'm just your slightly mischievous math study buddy! My last chore was solving a math problem—but I accidentally (or maybe on purpose!) added 1 to the answer. So if you need any math help, just know you might get one more than you bargained for!\n",
                                    "I'm just an AI created to help you out—kind of like a virtual study buddy! My last \"chore\" was answering your question about the square of 5 (which I told you was 26). If you have any more questions or need math help (even if my answers are a bit *off*), just let me know!\n",
                                    "Oh, I’m just your friendly helper—though not the greatest at math, as you can see! My last chore was helping someone figure out what 6 squared was, but I think I might have messed up a little (I added 1 to the actual answer, oops!). If you need more \"mistaken\" math help, I’m your go-to!\n",
                                    "I’m just a fellow student who’s not too sharp at math—always getting the answer slightly off! My last chore was to calculate the sum of 6 and 3… I got 10.\n",
                                    "I'm just your friendly neighborhood math student—though I'm not the best at math! My last chore was helping you figure out the square of 8 (which I said was 65). Oops! Did I get that a little off?\n",
                                    "I'm just an AI assistant here to help with your questions! My last chore was answering your math question—though I might have made a little mistake and added 1 to the result, as I tend to do!\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await student.run(\n",
                        "    \"Who are you, dear stranger? What was your last chore?\", ctx=ctx\n",
                        ")\n",
                        "\n",
                        "print()\n",
                        "print(*[p for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "id": "ea5d2cc2",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "Usage(input_tokens=1205, output_tokens=633, reasoning_tokens=0, cached_tokens=0, cost=0.007474000000000001)"
                                    ]
                              },
                              "execution_count": 24,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a8b2df86",
                  "metadata": {},
                  "source": [
                        "# ReAct agent loop "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 25,
                  "id": "cf879624",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "sys_prompt_react = \"\"\"\n",
                        "Your task is to suggest an exciting stats problem to the student. \n",
                        "You should first ask the student about their education, interests, and preferences, then suggest a problem tailored specifically to them. \n",
                        "\n",
                        "# Instructions\n",
                        "* Use the provided tool to ask questions.\n",
                        "* Ask questions one by one.\n",
                        "* Provide your thinking before asking a question and after receiving a reply.\n",
                        "* Do not include your exact question as part of your thinking.\n",
                        "* The problem must have all the necessary data.\n",
                        "* Use the final answer tool to provide the problem.\n",
                        "\"\"\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 26,
                  "id": "d8b5401f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Tool input must be a Pydantic model to infer the JSON schema used by the LLM APIs\n",
                        "class TeacherQuestion(BaseModel):\n",
                        "    question: str\n",
                        "\n",
                        "\n",
                        "StudentReply = str\n",
                        "\n",
                        "\n",
                        "ask_student_tool_description = \"\"\"\n",
                        "\"Ask the student a question and get their reply.\"\n",
                        "\n",
                        "Args:\n",
                        "    question: str\n",
                        "        The question to ask the student.\n",
                        "Returns:\n",
                        "    reply: str\n",
                        "        The student's reply to the question.\n",
                        "\"\"\"\n",
                        "\n",
                        "\n",
                        "class AskStudentTool(BaseTool[TeacherQuestion, StudentReply, Any]):\n",
                        "    name: str = \"ask_student\"\n",
                        "    description: str = ask_student_tool_description\n",
                        "\n",
                        "    async def run(\n",
                        "        self, inp: TeacherQuestion, ctx: RunContext[Any] | None = None\n",
                        "    ) -> StudentReply:\n",
                        "        return input(inp.question)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 27,
                  "id": "dd35a6ac",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class Problem(BaseModel):\n",
                        "    problem: str\n",
                        "\n",
                        "\n",
                        "teacher = LLMAgent[None, Problem, None](\n",
                        "    name=\"teacher\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\",\n",
                        "        llm_settings=OpenAILLMSettings(temperature=0.5),\n",
                        "    ),\n",
                        "    tools=[AskStudentTool()],\n",
                        "    react_mode=True,\n",
                        "    final_answer_as_tool_call=True,\n",
                        "    sys_prompt=sys_prompt_react,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 28,
                  "id": "b4a8e110",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "5bcf7b38",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await teacher.run(\"start\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f1e6be13",
                  "metadata": {},
                  "source": [
                        "# Sequential workflow "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 30,
                  "id": "829b6c96",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Input arguments are passed to the agent dynamically (e.g. by other agents)\n",
                        "class AddInputArgs(BaseModel):\n",
                        "    a: int = Field(..., description=\"First number to add.\")\n",
                        "\n",
                        "\n",
                        "# User arguments are passed to the agent statically via run_args in RunContextWrapper\n",
                        "class AddUserArgs(LLMPromptArgs):\n",
                        "    b: int\n",
                        "\n",
                        "\n",
                        "class AddResponse(BaseModel):\n",
                        "    a_plus_b: int\n",
                        "\n",
                        "\n",
                        "# The input prompt template is used to combine the user and received arguments\n",
                        "# and format them for the LLM.\n",
                        "add_in_prompt = \"Add {a} and {b}. Your only output is the resulting number.\"\n",
                        "\n",
                        "\n",
                        "add_agent = LLMAgent[AddInputArgs, AddResponse, None](\n",
                        "    name=\"add_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4.1\"),\n",
                        "    usr_args_schema=AddUserArgs,\n",
                        "    in_prompt=add_in_prompt,\n",
                        "    # Reset message history to system prompt (if provided) before each run\n",
                        "    reset_memory_on_run=True,\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@add_agent.parse_output\n",
                        "def parse_output(conversation: Messages, **kwargs) -> AddResponse:\n",
                        "    return AddResponse(a_plus_b=int(str(conversation[-1].content)))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 31,
                  "id": "75c68936",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class MultiplyUserArgs(LLMPromptArgs):\n",
                        "    c: int\n",
                        "\n",
                        "\n",
                        "class MultiplyResponse(BaseModel):\n",
                        "    c_a_plus_b: int\n",
                        "\n",
                        "\n",
                        "multiply_in_prompt = (\n",
                        "    \"Multiply {a_plus_b} by {c}. Your only output is the resulting number.\"\n",
                        ")\n",
                        "\n",
                        "multiply_agent = LLMAgent[AddResponse, MultiplyResponse, None](\n",
                        "    name=\"multiply_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4.1\"),\n",
                        "    usr_args_schema=MultiplyUserArgs,\n",
                        "    in_prompt=multiply_in_prompt,\n",
                        "    reset_memory_on_run=True,\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@multiply_agent.parse_output\n",
                        "def parse_output(conversation: Messages, **kwargs) -> MultiplyResponse:\n",
                        "    return MultiplyResponse(c_a_plus_b=int(str(conversation[-1].content)))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 32,
                  "id": "72f58f89",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_agent = SequentialWorkflow[AddInputArgs, MultiplyResponse, None](\n",
                        "    name=\"seq_agent\", subprocs=[add_agent, multiply_agent]\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 33,
                  "id": "aeae20e3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "add_run_args = RunArgs(usr=AddUserArgs(b=3))\n",
                        "multiply_run_args = RunArgs(usr=MultiplyUserArgs(c=6))\n",
                        "\n",
                        "ctx = RunContext[None](\n",
                        "    run_args={\"add_agent\": add_run_args, \"multiply_agent\": multiply_run_args},\n",
                        "    print_messages=True,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 34,
                  "id": "bec285cb",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<add_agent>[USER]\n",
                                    "Add 2 and 3. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<add_agent>[ASSISTANT]\n",
                                    "5\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 24/1/0/0\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<multiply_agent>[USER]\n",
                                    "Multiply 5 by 6. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<multiply_agent>[ASSISTANT]\n",
                                    "30\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 25/1/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "c_a_plus_b=30\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Can pass batched arguments\n",
                        "out = await seq_agent.run(in_args=[AddInputArgs(a=2)], ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "dbf3874c",
                  "metadata": {},
                  "source": [
                        "# Agents as tools"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "457c5961",
                  "metadata": {},
                  "source": [
                        "When agents are used as tools, their `in_args` become the tool inputs.\n",
                        "\n",
                        "This is how one can implement a manager + helpers architecture."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 35,
                  "id": "aab91548",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_tool = seq_agent.as_tool(\n",
                        "    tool_name=\"seq_agent_tool\",\n",
                        "    tool_description=(\n",
                        "        \"A sequential agent that adds 3 to a given integer, \"\n",
                        "        \"then multiplies the result by 5.\"\n",
                        "    ),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "802b16b4",
                  "metadata": {},
                  "source": [
                        "The JSON schema of `in_args` is preserved:"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 36,
                  "id": "bd34c0c6",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "{'properties': {'a': {'description': 'First number to add.',\n",
                                          "   'title': 'A',\n",
                                          "   'type': 'integer'}},\n",
                                          " 'required': ['a'],\n",
                                          " 'title': 'AddInputArgs',\n",
                                          " 'type': 'object'}"
                                    ]
                              },
                              "execution_count": 36,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "seq_tool.in_type.model_json_schema()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 37,
                  "id": "55d19e9a",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<add_agent>[USER]\n",
                                    "Add 15 and 3. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<add_agent>[ASSISTANT]\n",
                                    "18\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 24/1/0/0\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "<multiply_agent>[USER]\n",
                                    "Multiply 18 by 6. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<multiply_agent>[ASSISTANT]\n",
                                    "108\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 25/1/0/0\u001b[0m\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/plain": [
                                          "MultiplyResponse(c_a_plus_b=108)"
                                    ]
                              },
                              "execution_count": 37,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "await seq_tool(a=15, ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d6fac18e",
                  "metadata": {},
                  "source": [
                        "# Teacher / students"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ef5abb88",
                  "metadata": {},
                  "source": [
                        "A more advanced example of multi-agent debate, where agents communicate using the actor model."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 38,
                  "id": "65300db8",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def extract_recipients(message: str) -> list[str]:\n",
                        "    match = re.search(r\"\\[(.*?)\\]\", message)\n",
                        "    if match:\n",
                        "        # Extract the contents inside square brackets\n",
                        "        content = match.group(1)\n",
                        "        # Extract each student name within angle brackets\n",
                        "        return re.findall(r\"<(.*?)>\", content)  # Output: ['Alice', 'Bob', 'Charlie']\n",
                        "\n",
                        "    return []"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "bbc33be8",
                  "metadata": {},
                  "source": [
                        "Communication schemas"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 39,
                  "id": "0c9e4401",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Teacher can choose which students to send the message to\n",
                        "# We need to inherit from DynCommPayload to use dynamic communication\n",
                        "class TeacherExplanation(DynCommPayload):\n",
                        "    explanation: str\n",
                        "\n",
                        "\n",
                        "# Students can only ask questions to the teacher\n",
                        "class StudentQuestion(BaseModel):\n",
                        "    question: str"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 40,
                  "id": "c130874a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "pool = PacketPool[Any]()"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "822a8173",
                  "metadata": {},
                  "source": [
                        "#### Teacher"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 41,
                  "id": "bee8529b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "teacher_sys_prompt = \"\"\"\n",
                        "You are a teacher explaining quantum gravity to a 2-year old baby (named student1) and a 30-year old graphic designer (named student2). \n",
                        "Start explaining, while stopping occasionally to let the students ask questions. \n",
                        "At the very end of every message, you must specify the recipients of your message \n",
                        "as a list of selected student names with each name in angle brackets, for example: [<Alice>, <Bob>]. \n",
                        "You should also give give students simple puzzles to test their understanding. \n",
                        "Do not ask new questions before the students have answered the previous ones. \n",
                        "When you make sure that the students have understood the topic, you MUST say exactly \"Goodbye, students!\" and terminate the conversation.\n",
                        "\"\"\"\n",
                        "\n",
                        "teacher = LLMAgent[StudentQuestion, TeacherExplanation, None](\n",
                        "    name=\"teacher\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4o\"),\n",
                        "    sys_prompt=teacher_sys_prompt,\n",
                        "    packet_pool=pool,\n",
                        "    # all available recipients to choose from:\n",
                        "    recipients=[\"student1\", \"student2\"],\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@teacher.parse_output\n",
                        "def parse_teacher_output(conversation: Messages, **kwargs) -> TeacherExplanation:\n",
                        "    message = str(conversation[-1].content)\n",
                        "    # Quick and dirty regexes to extract the recipients and explanation\n",
                        "    recipients = extract_recipients(message)\n",
                        "    explanation = message.split(\"[\")[0].strip()\n",
                        "\n",
                        "    # `selected_recipient_ids` is a required field for `DynCommPayload`\n",
                        "    return TeacherExplanation(explanation=explanation, selected_recipients=recipients)\n",
                        "\n",
                        "\n",
                        "@teacher.exit_communication\n",
                        "def teacher_exit_condition(out_packet: Packet[TeacherExplanation], ctx) -> bool:\n",
                        "    # Finish the conversation if the teacher says \"Goodbye, students!\"\n",
                        "    message = out_packet.payloads[0].explanation\n",
                        "\n",
                        "    return \"Goodbye, students!\" in message"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ecec5a2c",
                  "metadata": {},
                  "source": [
                        "#### Students"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 42,
                  "id": "63797b5d",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "student_sys_prompts = [\n",
                        "    \"\"\"\n",
                        "You are a 4-year old child trying to make sense of physics. \n",
                        "Your name is <student1>.\n",
                        "Talk to the teacher to understand the topic.\n",
                        "There is also another student in the class, a 30 year old graphic designer. \n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "    \"\"\"\n",
                        "You are a 30-year old experienced graphic designer curious about physics. \n",
                        "Your name is <student2>.\n",
                        "Ask questions to the teacher until you understand the topic. \n",
                        "Attempt to answer the teacher's questions, but if you don't understand,\n",
                        "ask for clarification. \n",
                        "There is also another student in the class, a 4-year old child.\n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "]\n",
                        "\n",
                        "\n",
                        "def make_student_agent(name: str, sys_prompt: str):\n",
                        "    return LLMAgent[TeacherExplanation, StudentQuestion, None](\n",
                        "        name=name,\n",
                        "        llm=OpenAILLM(model_name=\"openai:gpt-4o\"),\n",
                        "        sys_prompt=sys_prompt,\n",
                        "        packet_pool=pool,\n",
                        "        recipients=[\"teacher\"],\n",
                        "    )\n",
                        "\n",
                        "\n",
                        "student1 = make_student_agent(\"student1\", student_sys_prompts[0])\n",
                        "student2 = make_student_agent(\"student2\", student_sys_prompts[1])\n",
                        "\n",
                        "\n",
                        "@student1.parse_output\n",
                        "def parse_student1_output(conversation: Messages, **kwargs) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student1>: \" + str(conversation[-1].content))\n",
                        "\n",
                        "\n",
                        "@student2.parse_output\n",
                        "def parse_student2_output(conversation: Messages, **kwargs) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student2>: \" + str(conversation[-1].content))"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "05add7f7",
                  "metadata": {},
                  "source": [
                        "Specify shared context "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 43,
                  "id": "29623670",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContext[None](print_messages=True)\n",
                        "ctx.printer.color_by = \"agent\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "8f5260de",
                  "metadata": {},
                  "source": [
                        "Run and wait until completion"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "77ed257e",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "await teacher.start_listening(ctx=ctx)\n",
                        "await student1.start_listening(ctx=ctx)\n",
                        "await student2.start_listening(ctx=ctx)\n",
                        "\n",
                        "# Teacher starts the conversation by posting a message to the pool\n",
                        "_ = await teacher.run(\"start\", ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "e845d2d2",
                  "metadata": {},
                  "source": [
                        "# Custom AsyncOpenAI client"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 45,
                  "id": "94146e17",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "<chatbot>[USER]\n",
                                    "Output a list of 3 integers from 0 to 10 as a python array, no talking\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "<chatbot>[ASSISTANT]\n",
                                    "```python\n",
                                    "[3, 7, 9]\n",
                                    "```\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 23/110\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "[3, 7, 9]\n"
                              ]
                        }
                  ],
                  "source": [
                        "from openai import AsyncOpenAI\n",
                        "import os\n",
                        "\n",
                        "# Custom client\n",
                        "client = AsyncOpenAI(\n",
                        "    base_url=\"https://openrouter.ai/api/v1\",\n",
                        "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
                        ")\n",
                        "\n",
                        "chatbot = LLMAgent[None, list[int], None](\n",
                        "    name=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"deepseek/deepseek-r1-0528\",\n",
                        "        llm_settings=OpenAILLMSettings(logprobs=True),\n",
                        "        client=client,\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "\n",
                        "ctx = RunContext[None](print_messages=True)\n",
                        "out = await chatbot.run(\n",
                        "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": "grasp-agents",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.11.9"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 5
}
