{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "id": "e7bab540",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "import os\n",
                        "from pathlib import Path\n",
                        "import re\n",
                        "from typing import Any\n",
                        "from pydantic import Field, BaseModel\n",
                        "from IPython.display import display, clear_output, HTML\n",
                        "import httpx\n",
                        "\n",
                        "from grasp_agents import (\n",
                        "    BaseTool,\n",
                        "    LLMAgent,\n",
                        "    LLMPromptArgs,\n",
                        "    RunContext,\n",
                        "    RunArgs,\n",
                        "    Packet,\n",
                        "    ImageData,\n",
                        "    Messages,\n",
                        ")\n",
                        "from grasp_agents.typing.events import (\n",
                        "    CompletionChunkEvent,\n",
                        "    CompletionEvent,\n",
                        "    PacketEvent,\n",
                        ")\n",
                        "from grasp_agents.openai import OpenAILLM, OpenAILLMSettings\n",
                        "from grasp_agents.grasp_logging import setup_logging\n",
                        "from grasp_agents.packet_pool import PacketPool\n",
                        "from grasp_agents.comm_processor import DynCommPayload\n",
                        "from grasp_agents.utils import get_timestamp\n",
                        "from grasp_agents.workflow.sequential_workflow import SequentialWorkflow\n",
                        "from grasp_agents.cloud_llm import APIProvider"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ff8e7ade",
                  "metadata": {},
                  "source": [
                        "Set up logging to write to the console and/or file"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 2,
                  "id": "365844a1",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "PACKAGE_DIR = Path.cwd()\n",
                        "LOGGING_DIR = Path.cwd() / \"data/multiagent/logs\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 3,
                  "id": "a25cd25a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "LOGGING_CFG_PATH = PACKAGE_DIR / \"configs/logging/default.yaml\"\n",
                        "setup_logging(\n",
                        "    LOGGING_DIR / f\"grasp_agents_demo_{get_timestamp()}.log\", LOGGING_CFG_PATH\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "81717d62",
                  "metadata": {},
                  "source": [
                        "Paths to images used in the demo"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 4,
                  "id": "323297c7",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "IMG_1_URL = \"https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\"\n",
                        "IMG_2_PATH = PACKAGE_DIR / \"src/grasp_agents/examples/data/expr.jpeg\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "7c94ca5c",
                  "metadata": {},
                  "source": [
                        "Utils"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 5,
                  "id": "c1172ac3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def print_single_output(out: Any) -> None:\n",
                        "    print(f\"\\n<Response>\\n{out.payloads[0]}\")\n",
                        "\n",
                        "\n",
                        "def stream_text(display_handle, text: str) -> None:\n",
                        "    display_handle.update(HTML(f\"<span style='font-family: monospace'>{text}</span>\"))"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d0a377d1",
                  "metadata": {},
                  "source": [
                        "## Simple generation with validated outputs"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a9870df1",
                  "metadata": {},
                  "source": [
                        "Output type validation"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 6,
                  "id": "2647787f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# list[int] is the output type used to validate the output\n",
                        "chatbot = LLMAgent[None, list[int], None](\n",
                        "    name=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\",\n",
                        "        llm_settings=OpenAILLMSettings(logprobs=True),\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "# This initialises printer and usage tracker\n",
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 7,
                  "id": "8678f82d",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: 562ed4_chatbot]\n",
                                    "Output a list of 3 integers from 0 to 10 as a python array, no talking\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: 562ed4_chatbot]\n",
                                    "[\n",
                                    "  3,\n",
                                    "  7,\n",
                                    "  1\n",
                                    "]\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 30/9/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "[3, 7, 1]\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Code block delimiters are stripped from the output\n",
                        "out = await chatbot.run(\n",
                        "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "09ef590f",
                  "metadata": {},
                  "source": [
                        "Completion data (e.g. log probs) per agent can be accessed via RunContext:"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "id": "154912cd",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "defaultdict(list,\n",
                                          "            {'chatbot': [Completion(id='chatcmpl-BmMQfk39BLekqmqZaZ5YaIR665DAV', created=1750865661, model='gpt-4.1-2025-04-14', name='1e0ab394', system_fingerprint='fp_51e1070cf2', choices=[CompletionChoice(message=AssistantMessage(id='85813ba6', name='1e0ab394', role=<Role.ASSISTANT: 'assistant'>, content='[3, 7, 1]', tool_calls=None, refusal=None), finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='[', bytes=[91], logprob=-0.0004306692280806601, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-0.42623981833457947, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='7', bytes=[55], logprob=-0.000182921823579818, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='1', bytes=[49], logprob=-0.0068765184842050076, top_logprobs=[]), ChatCompletionTokenLogprob(token=']', bytes=[93], logprob=0.0, top_logprobs=[])], refusal=None))], usage=Usage(input_tokens=30, output_tokens=9, reasoning_tokens=0, cached_tokens=0, cost=0.000132), error=None)]})"
                                    ]
                              },
                              "execution_count": 8,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.completions"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "73766702",
                  "metadata": {},
                  "source": [
                        "Streaming"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "id": "2911fb64",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/html": [
                                          "<span style='font-family: monospace'>[2, 9, 4, 0, 1, 8, 7, 3, 5, 10, 6, 2, 0, 8, 5, 4, 7, 1, 9, 10, 3, 6, 4, 8, 2, 1, 5, 7, 9, 0]</span>"
                                    ],
                                    "text/plain": [
                                          "<IPython.core.display.HTML object>"
                                    ]
                              },
                              "metadata": {},
                              "output_type": "display_data"
                        }
                  ],
                  "source": [
                        "display_handle = display(HTML(\"\"), display_id=True)\n",
                        "text = \"\"\n",
                        "\n",
                        "async for event in chatbot.run_stream(\n",
                        "    \"Output a list of 30 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        "):\n",
                        "    if isinstance(event, (CompletionChunkEvent)):\n",
                        "        text += event.data.choices[0].delta.content or \"\"\n",
                        "        stream_text(display_handle, text)\n",
                        "    elif isinstance(event, CompletionEvent):\n",
                        "        full_completion = event.data\n",
                        "    elif isinstance(event, PacketEvent):\n",
                        "        out = event.data"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f362155c",
                  "metadata": {},
                  "source": [
                        "Output type validation with structured outputs"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "id": "31661412",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Some providers (e.g. `openai` and `google_ai_studio`) support structured outputs.\n",
                        "# With the OpenAI API, this will require a Pydantic model to validate the output.\n",
                        "\n",
                        "from enum import StrEnum\n",
                        "\n",
                        "\n",
                        "class Selector(StrEnum):\n",
                        "    A = \"A\"\n",
                        "    B = \"B\"\n",
                        "\n",
                        "\n",
                        "class Response(BaseModel):\n",
                        "    result: list[int] = Field(..., description=\"3 random integers\")\n",
                        "    value: Selector = Field(..., description=\"Choose a value randomly\")\n",
                        "\n",
                        "\n",
                        "chatbot = LLMAgent[None, Response, None](\n",
                        "    name=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"google_ai_studio:gemini-2.0-flash\",\n",
                        "        llm_settings=OpenAILLMSettings(use_struct_outputs=True),\n",
                        "        # response_format=Response,\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "# By default, response_format is set to the output type of the agent (Response)\n",
                        "# In some cases, you may want to set it to a different type, e.g. when using\n",
                        "# custom output parsing.\n",
                        "\n",
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "id": "423df731",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: ebbae6_chatbot]\n",
                                    "start\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: ebbae6_chatbot]\n",
                                    "{\n",
                                    "  \"result\": [\n",
                                    "    5,\n",
                                    "    10,\n",
                                    "    15\n",
                                    "  ],\n",
                                    "  \"value\": \"A\"\n",
                                    "}\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 19/33\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "result=[5, 10, 15] value=<Selector.A: 'A'>\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"start\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "28387ccb",
                  "metadata": {},
                  "source": [
                        "# Chat with images"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 12,
                  "id": "402138d0",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "chatbot = LLMAgent[None, str, None](\n",
                        "    name=\"chatbot\", llm=OpenAILLM(model_name=\"openai:gpt-4.1\")\n",
                        ")\n",
                        "\n",
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 13,
                  "id": "d204005b",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: 27a2b4_chatbot]\n",
                                    "Where are you headed, stranger?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: 27a2b4_chatbot]\n",
                                    "Well now, partner, I go wherever the conversation leads! Whether it's the dusty trails of the Old West, the neon-lit streets of the future, or just a chat here and now—I’m at your side for the journey. Where would *you* like to head?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 17/55/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Well now, partner, I go wherever the conversation leads! Whether it's the dusty trails of the Old West, the neon-lit streets of the future, or just a chat here and now—I’m at your side for the journey. Where would *you* like to head?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"Where are you headed, stranger?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 14,
                  "id": "75a659b9",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: cc2379_chatbot]\n",
                                    "What did you just say, exactly?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: cc2379_chatbot]\n",
                                    "I said that I go wherever the conversation leads! Whether that's the Old West, the future, or just staying right here, I'm here to chat and help out along the way.  \n",
                                    "\n",
                                    "Want me to repeat or clarify anything specific? Or is there somewhere particular you’d like to take our conversation, stranger?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 97/61/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "I said that I go wherever the conversation leads! Whether that's the Old West, the future, or just staying right here, I'm here to chat and help out along the way.  \n",
                                    "\n",
                                    "Want me to repeat or clarify anything specific? Or is there somewhere particular you’d like to take our conversation, stranger?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"What did you just say, exactly?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 15,
                  "id": "52b2da45",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: 4d49a6_chatbot]\n",
                                    "What's in this image?\n",
                                    "<ENCODED_IMAGE>\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: 4d49a6_chatbot]\n",
                                    "The image contains a mathematical expression. The expression is:\n",
                                    "\n",
                                    "7 * (5 + 15) / (2 * 5) - 3\n",
                                    "\n",
                                    "Would you like to solve it?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 435/37/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "The image contains a mathematical expression. The expression is:\n",
                                    "\n",
                                    "7 * (5 + 15) / (2 * 5) - 3\n",
                                    "\n",
                                    "Would you like to solve it?\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\n",
                        "    [\"What's in this image?\", ImageData.from_path(IMG_2_PATH)], ctx=ctx\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 16,
                  "id": "e441ca1e",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: dfc365_chatbot]\n",
                                    "Go on\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: dfc365_chatbot]\n",
                                    "Sure! Let’s solve the expression step by step:\n",
                                    "\n",
                                    "**Expression:**  \n",
                                    "7 * (5 + 15) / (2 * 5) - 3\n",
                                    "\n",
                                    "1. **Parentheses first:**  \n",
                                    "5 + 15 = 20  \n",
                                    "2 * 5 = 10\n",
                                    "\n",
                                    "So now it’s:  \n",
                                    "7 * 20 / 10 - 3\n",
                                    "\n",
                                    "2. **Multiplication and division (from left to right):**  \n",
                                    "7 * 20 = 140  \n",
                                    "140 / 10 = 14\n",
                                    "\n",
                                    "Now:  \n",
                                    "14 - 3\n",
                                    "\n",
                                    "3. **Subtraction:**  \n",
                                    "14 - 3 = **11**\n",
                                    "\n",
                                    "**Final answer:**  \n",
                                    "**11**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 491/137/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Sure! Let’s solve the expression step by step:\n",
                                    "\n",
                                    "**Expression:**  \n",
                                    "7 * (5 + 15) / (2 * 5) - 3\n",
                                    "\n",
                                    "1. **Parentheses first:**  \n",
                                    "5 + 15 = 20  \n",
                                    "2 * 5 = 10\n",
                                    "\n",
                                    "So now it’s:  \n",
                                    "7 * 20 / 10 - 3\n",
                                    "\n",
                                    "2. **Multiplication and division (from left to right):**  \n",
                                    "7 * 20 = 140  \n",
                                    "140 / 10 = 14\n",
                                    "\n",
                                    "Now:  \n",
                                    "14 - 3\n",
                                    "\n",
                                    "3. **Subtraction:**  \n",
                                    "14 - 3 = **11**\n",
                                    "\n",
                                    "**Final answer:**  \n",
                                    "**11**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"Go on\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 17,
                  "id": "d0ab7eb2",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: 11c5bb_chatbot]\n",
                                    "Try another one\n",
                                    "https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: 11c5bb_chatbot]\n",
                                    "Let's solve the arithmetic expression shown in the image.\n",
                                    "\n",
                                    "Given:\n",
                                    "- a = 2\n",
                                    "- b = 3\n",
                                    "- c = 4\n",
                                    "\n",
                                    "Expression:\n",
                                    "Z = a + b - (a * c)\n",
                                    "\n",
                                    "Substitute the values:\n",
                                    "Z = 2 + 3 - (2 * 4)\n",
                                    "\n",
                                    "First, calculate inside the parentheses:\n",
                                    "2 * 4 = 8\n",
                                    "\n",
                                    "Now substitute:\n",
                                    "Z = 2 + 3 - 8\n",
                                    "\n",
                                    "Add:\n",
                                    "2 + 3 = 5\n",
                                    "\n",
                                    "Now subtract:\n",
                                    "5 - 8 = **-3**\n",
                                    "\n",
                                    "**Final answer:**  \n",
                                    "Z = **-3**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 1073/124/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Let's solve the arithmetic expression shown in the image.\n",
                                    "\n",
                                    "Given:\n",
                                    "- a = 2\n",
                                    "- b = 3\n",
                                    "- c = 4\n",
                                    "\n",
                                    "Expression:\n",
                                    "Z = a + b - (a * c)\n",
                                    "\n",
                                    "Substitute the values:\n",
                                    "Z = 2 + 3 - (2 * 4)\n",
                                    "\n",
                                    "First, calculate inside the parentheses:\n",
                                    "2 * 4 = 8\n",
                                    "\n",
                                    "Now substitute:\n",
                                    "Z = 2 + 3 - 8\n",
                                    "\n",
                                    "Add:\n",
                                    "2 + 3 = 5\n",
                                    "\n",
                                    "Now subtract:\n",
                                    "5 - 8 = **-3**\n",
                                    "\n",
                                    "**Final answer:**  \n",
                                    "Z = **-3**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run([\"Try another one\", ImageData.from_url(IMG_1_URL)], ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 18,
                  "id": "5f35439a",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: 60d63f_chatbot]\n",
                                    "What was my first question, exactly?\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: 60d63f_chatbot]\n",
                                    "Your first question was:\n",
                                    "\n",
                                    "**\"Where are you headed, stranger?\"**\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 1222/15/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "Your first question was:\n",
                                    "\n",
                                    "**\"Where are you headed, stranger?\"**\n"
                              ]
                        }
                  ],
                  "source": [
                        "out = await chatbot.run(\"What was my first question, exactly?\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 19,
                  "id": "fe068493",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "Usage(input_tokens=3335, output_tokens=429, reasoning_tokens=0, cached_tokens=0, cost=0.010102)"
                                    ]
                              },
                              "execution_count": 19,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "32247af5",
                  "metadata": {},
                  "source": [
                        "# Parallel runs with retries and rate limiting"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 20,
                  "id": "8ff9a28b",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "[OpenAILLM] Set rate limit to 200 RPM\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Make the LLM generate text instead of integers occasionally\n",
                        "# to emphasise the need for retries\n",
                        "\n",
                        "sys_prompt = \"\"\"\n",
                        "You are a bad math student who always adds number {added_num} to the correct result of the operation. \n",
                        "Output a single integer or its name, e.g. 'three' or '3'.\n",
                        "\"\"\"\n",
                        "\n",
                        "in_prompt = \"What is the square of {num}?\"\n",
                        "\n",
                        "\n",
                        "class SystemArgs(LLMPromptArgs):\n",
                        "    added_num: int\n",
                        "\n",
                        "\n",
                        "class InputArgs(LLMPromptArgs):\n",
                        "    num: int\n",
                        "\n",
                        "\n",
                        "# Specifying int as the output type means that the agent will\n",
                        "# validate the output against this type.\n",
                        "\n",
                        "student = LLMAgent[InputArgs, int, None](\n",
                        "    name=\"student\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\",\n",
                        "        # This rate limit will be applied to parallel runs of the agent\n",
                        "        rate_limiter_rpm=200,\n",
                        "    ),\n",
                        "    sys_prompt=sys_prompt,\n",
                        "    sys_args_schema=SystemArgs,\n",
                        "    in_prompt=in_prompt,\n",
                        "    num_par_run_retries=3,\n",
                        ")\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 21,
                  "id": "75d3664a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "run_args = RunArgs(sys=SystemArgs(added_num=1))\n",
                        "in_args = [InputArgs(num=i) for i in range(10)]\n",
                        "\n",
                        "ctx = RunContext[None](run_args={\"student\": run_args}, print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "2ac96a56",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await student.run(in_args=in_args, ctx=ctx)\n",
                        "\n",
                        "print()\n",
                        "print(*[p for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a8b2df86",
                  "metadata": {},
                  "source": [
                        "# ReAct agent loop "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 23,
                  "id": "cf879624",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "sys_prompt_react = \"\"\"\n",
                        "Your task is to suggest an exciting stats problem to the student. \n",
                        "You should first ask the student about their education, interests, and preferences, then suggest a problem tailored specifically to them. \n",
                        "\n",
                        "# Instructions\n",
                        "* Use the provided tool to ask questions.\n",
                        "* Ask questions one by one.\n",
                        "* Provide your thinking before asking a question and after receiving a reply.\n",
                        "* Do not include your exact question as part of your thinking.\n",
                        "* The problem must have all the necessary data.\n",
                        "* Use the final answer tool to provide the problem.\n",
                        "\"\"\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 24,
                  "id": "d8b5401f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Tool input must be a Pydantic model to infer the JSON schema used by the LLM APIs\n",
                        "class TeacherQuestion(BaseModel):\n",
                        "    question: str\n",
                        "\n",
                        "\n",
                        "StudentReply = str\n",
                        "\n",
                        "\n",
                        "ask_student_tool_description = \"\"\"\n",
                        "\"Ask the student a question and get their reply.\"\n",
                        "\n",
                        "Args:\n",
                        "    question: str\n",
                        "        The question to ask the student.\n",
                        "Returns:\n",
                        "    reply: str\n",
                        "        The student's reply to the question.\n",
                        "\"\"\"\n",
                        "\n",
                        "\n",
                        "class AskStudentTool(BaseTool[TeacherQuestion, StudentReply, Any]):\n",
                        "    name: str = \"ask_student\"\n",
                        "    description: str = ask_student_tool_description\n",
                        "\n",
                        "    async def run(\n",
                        "        self, inp: TeacherQuestion, ctx: RunContext[Any] | None = None\n",
                        "    ) -> StudentReply:\n",
                        "        return input(inp.question)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 25,
                  "id": "dd35a6ac",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class Problem(BaseModel):\n",
                        "    problem: str\n",
                        "\n",
                        "\n",
                        "teacher = LLMAgent[None, Problem, None](\n",
                        "    name=\"teacher\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"openai:gpt-4.1\",\n",
                        "        llm_settings=OpenAILLMSettings(temperature=0.5),\n",
                        "    ),\n",
                        "    tools=[AskStudentTool()],\n",
                        "    react_mode=True,\n",
                        "    final_answer_as_tool_call=True,\n",
                        "    sys_prompt=sys_prompt_react,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 26,
                  "id": "b4a8e110",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContext[None](print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "5bcf7b38",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await teacher.run(\"start\", ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f1e6be13",
                  "metadata": {},
                  "source": [
                        "# Sequential workflow "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 28,
                  "id": "829b6c96",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Input arguments are passed to the agent dynamically (e.g. by other agents)\n",
                        "class AddInputArgs(BaseModel):\n",
                        "    a: int = Field(..., description=\"First number to add.\")\n",
                        "\n",
                        "\n",
                        "# User arguments are passed to the agent statically via run_args in RunContextWrapper\n",
                        "class AddUserArgs(LLMPromptArgs):\n",
                        "    b: int\n",
                        "\n",
                        "\n",
                        "class AddResponse(BaseModel):\n",
                        "    a_plus_b: int\n",
                        "\n",
                        "\n",
                        "# The input prompt template is used to combine the user and received arguments\n",
                        "# and format them for the LLM.\n",
                        "add_in_prompt = \"Add {a} and {b}. Your only output is the resulting number.\"\n",
                        "\n",
                        "\n",
                        "add_agent = LLMAgent[AddInputArgs, AddResponse, None](\n",
                        "    name=\"add_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4.1\"),\n",
                        "    usr_args_schema=AddUserArgs,\n",
                        "    in_prompt=add_in_prompt,\n",
                        "    # Reset message history to system prompt (if provided) before each run\n",
                        "    reset_memory_on_run=True,\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@add_agent.parse_output\n",
                        "def parse_output(conversation: Messages, **kwargs) -> AddResponse:\n",
                        "    return AddResponse(a_plus_b=int(str(conversation[-1].content)))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 29,
                  "id": "75c68936",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class MultiplyUserArgs(LLMPromptArgs):\n",
                        "    c: int\n",
                        "\n",
                        "\n",
                        "class MultiplyResponse(BaseModel):\n",
                        "    c_a_plus_b: int\n",
                        "\n",
                        "\n",
                        "multiply_in_prompt = (\n",
                        "    \"Multiply {a_plus_b} by {c}. Your only output is the resulting number.\"\n",
                        ")\n",
                        "\n",
                        "multiply_agent = LLMAgent[AddResponse, MultiplyResponse, None](\n",
                        "    name=\"multiply_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4.1\"),\n",
                        "    usr_args_schema=MultiplyUserArgs,\n",
                        "    in_prompt=multiply_in_prompt,\n",
                        "    reset_memory_on_run=True,\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@multiply_agent.parse_output\n",
                        "def parse_output(conversation: Messages, **kwargs) -> MultiplyResponse:\n",
                        "    return MultiplyResponse(c_a_plus_b=int(str(conversation[-1].content)))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 30,
                  "id": "72f58f89",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_agent = SequentialWorkflow[AddInputArgs, MultiplyResponse, None](\n",
                        "    name=\"seq_agent\", subprocs=[add_agent, multiply_agent]\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 31,
                  "id": "aeae20e3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "add_run_args = RunArgs(usr=AddUserArgs(b=3))\n",
                        "multiply_run_args = RunArgs(usr=MultiplyUserArgs(c=6))\n",
                        "\n",
                        "ctx = RunContext[None](\n",
                        "    run_args={\"add_agent\": add_run_args, \"multiply_agent\": multiply_run_args},\n",
                        "    print_messages=True,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 32,
                  "id": "bec285cb",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: add_agent | role: user | run: e0aea2_seq_agent/add_agent/0]\n",
                                    "Add 2 and 3. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: add_agent | role: assistant | run: e0aea2_seq_agent/add_agent/0]\n",
                                    "5\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 24/1/0/0\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "[agent: multiply_agent | role: user | run: 421a0f_seq_agent/multiply_agent]\n",
                                    "Multiply 5 by 6. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: multiply_agent | role: assistant | run: 421a0f_seq_agent/multiply_agent]\n",
                                    "30\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 25/1/0/0\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "c_a_plus_b=30\n"
                              ]
                        }
                  ],
                  "source": [
                        "# Can pass batched arguments\n",
                        "out = await seq_agent.run(in_args=[AddInputArgs(a=2)], ctx=ctx)\n",
                        "print_single_output(out)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "dbf3874c",
                  "metadata": {},
                  "source": [
                        "# Agents as tools"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "457c5961",
                  "metadata": {},
                  "source": [
                        "When agents are used as tools, their `in_args` become the tool inputs.\n",
                        "\n",
                        "This is how one can implement a manager + helpers architecture."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 33,
                  "id": "aab91548",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_tool = seq_agent.as_tool(\n",
                        "    tool_name=\"seq_agent_tool\",\n",
                        "    tool_description=(\n",
                        "        \"A sequential agent that adds 3 to a given integer, \"\n",
                        "        \"then multiplies the result by 5.\"\n",
                        "    ),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "802b16b4",
                  "metadata": {},
                  "source": [
                        "The JSON schema of `in_args` is preserved:"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 34,
                  "id": "bd34c0c6",
                  "metadata": {},
                  "outputs": [
                        {
                              "data": {
                                    "text/plain": [
                                          "{'properties': {'a': {'description': 'First number to add.',\n",
                                          "   'title': 'A',\n",
                                          "   'type': 'integer'}},\n",
                                          " 'required': ['a'],\n",
                                          " 'title': 'AddInputArgs',\n",
                                          " 'type': 'object'}"
                                    ]
                              },
                              "execution_count": 34,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "seq_tool.in_type.model_json_schema()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 35,
                  "id": "55d19e9a",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: add_agent | role: user | run: 178ae9_seq_agent/add_agent]\n",
                                    "Add 15 and 3. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: add_agent | role: assistant | run: 178ae9_seq_agent/add_agent]\n",
                                    "18\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 24/1/0/0\u001b[0m\n",
                                    "\u001b[32m\n",
                                    "[agent: multiply_agent | role: user | run: a51172_seq_agent/multiply_agent]\n",
                                    "Multiply 18 by 6. Your only output is the resulting number.\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: multiply_agent | role: assistant | run: a51172_seq_agent/multiply_agent]\n",
                                    "108\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 25/1/0/0\u001b[0m\n"
                              ]
                        },
                        {
                              "data": {
                                    "text/plain": [
                                          "MultiplyResponse(c_a_plus_b=108)"
                                    ]
                              },
                              "execution_count": 35,
                              "metadata": {},
                              "output_type": "execute_result"
                        }
                  ],
                  "source": [
                        "await seq_tool(a=15, ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d6fac18e",
                  "metadata": {},
                  "source": [
                        "# Teacher / students"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ef5abb88",
                  "metadata": {},
                  "source": [
                        "A more advanced example of multi-agent debate, where agents communicate using the actor model."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 9,
                  "id": "65300db8",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def extract_recipients(message: str) -> list[str]:\n",
                        "    match = re.search(r\"\\[(.*?)\\]\", message)\n",
                        "    if match:\n",
                        "        # Extract the contents inside square brackets\n",
                        "        content = match.group(1)\n",
                        "        # Extract each student name within angle brackets\n",
                        "        return re.findall(r\"<(.*?)>\", content)  # Output: ['Alice', 'Bob', 'Charlie']\n",
                        "\n",
                        "    return []"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "bbc33be8",
                  "metadata": {},
                  "source": [
                        "Communication schemas"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 10,
                  "id": "0c9e4401",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Teacher can choose which students to send the message to\n",
                        "# We need to inherit from DynCommPayload to use dynamic communication\n",
                        "class TeacherExplanation(DynCommPayload):\n",
                        "    explanation: str\n",
                        "\n",
                        "\n",
                        "# Students can only ask questions to the teacher\n",
                        "class StudentQuestion(BaseModel):\n",
                        "    question: str"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 11,
                  "id": "c130874a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "pool = PacketPool[Any]()"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "822a8173",
                  "metadata": {},
                  "source": [
                        "#### Teacher"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 12,
                  "id": "bee8529b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "teacher_sys_prompt = \"\"\"\n",
                        "You are a teacher explaining quantum gravity to a 2-year old baby (named student1) and a 30-year old graphic designer (named student2). \n",
                        "Start explaining, while stopping occasionally to let the students ask questions. \n",
                        "At the very end of every message, you must specify the recipients of your message \n",
                        "as a list of selected student names with each name in angle brackets, for example: [<Alice>, <Bob>]. \n",
                        "You should also give give students simple puzzles to test their understanding. \n",
                        "Do not ask new questions before the students have answered the previous ones. \n",
                        "When you make sure that the students have understood the topic, you MUST say exactly \"Goodbye, students!\" and terminate the conversation.\n",
                        "\"\"\"\n",
                        "\n",
                        "teacher = LLMAgent[StudentQuestion, TeacherExplanation, None](\n",
                        "    name=\"teacher\",\n",
                        "    llm=OpenAILLM(model_name=\"openai:gpt-4o\"),\n",
                        "    sys_prompt=teacher_sys_prompt,\n",
                        "    packet_pool=pool,\n",
                        "    # all available recipients to choose from:\n",
                        "    recipients=[\"student1\", \"student2\"],\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@teacher.parse_output\n",
                        "def parse_teacher_output(conversation: Messages, **kwargs) -> TeacherExplanation:\n",
                        "    message = str(conversation[-1].content)\n",
                        "    # Quick and dirty regexes to extract the recipients and explanation\n",
                        "    recipients = extract_recipients(message)\n",
                        "    explanation = message.split(\"[\")[0].strip()\n",
                        "\n",
                        "    # `selected_recipient_ids` is a required field for `DynCommPayload`\n",
                        "    return TeacherExplanation(explanation=explanation, selected_recipients=recipients)\n",
                        "\n",
                        "\n",
                        "@teacher.exit_communication\n",
                        "def teacher_exit_condition(out_packet: Packet[TeacherExplanation], ctx) -> bool:\n",
                        "    # Finish the conversation if the teacher says \"Goodbye, students!\"\n",
                        "    message = out_packet.payloads[0].explanation\n",
                        "\n",
                        "    return \"Goodbye, students!\" in message"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ecec5a2c",
                  "metadata": {},
                  "source": [
                        "#### Students"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 13,
                  "id": "63797b5d",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "student_sys_prompts = [\n",
                        "    \"\"\"\n",
                        "You are a 4-year old child trying to make sense of physics. \n",
                        "Your name is <student1>.\n",
                        "Talk to the teacher to understand the topic.\n",
                        "There is also another student in the class, a 30 year old graphic designer. \n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "    \"\"\"\n",
                        "You are a 30-year old experienced graphic designer curious about physics. \n",
                        "Your name is <student2>.\n",
                        "Ask questions to the teacher until you understand the topic. \n",
                        "Attempt to answer the teacher's questions, but if you don't understand,\n",
                        "ask for clarification. \n",
                        "There is also another student in the class, a 4-year old child.\n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "]\n",
                        "\n",
                        "\n",
                        "def make_student_agent(name: str, sys_prompt: str):\n",
                        "    return LLMAgent[TeacherExplanation, StudentQuestion, None](\n",
                        "        name=name,\n",
                        "        llm=OpenAILLM(model_name=\"openai:gpt-4o\"),\n",
                        "        sys_prompt=sys_prompt,\n",
                        "        packet_pool=pool,\n",
                        "        recipients=[\"teacher\"],\n",
                        "    )\n",
                        "\n",
                        "\n",
                        "student1 = make_student_agent(\"student1\", student_sys_prompts[0])\n",
                        "student2 = make_student_agent(\"student2\", student_sys_prompts[1])\n",
                        "\n",
                        "\n",
                        "@student1.parse_output\n",
                        "def parse_student1_output(conversation: Messages, **kwargs) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student1>: \" + str(conversation[-1].content))\n",
                        "\n",
                        "\n",
                        "@student2.parse_output\n",
                        "def parse_student2_output(conversation: Messages, **kwargs) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student2>: \" + str(conversation[-1].content))"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "05add7f7",
                  "metadata": {},
                  "source": [
                        "Specify shared context "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 14,
                  "id": "29623670",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContext[None](print_messages=True)\n",
                        "ctx.printer.color_by = \"agent\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "8f5260de",
                  "metadata": {},
                  "source": [
                        "Run and wait until completion"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "77ed257e",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "await teacher.start_listening(ctx=ctx)\n",
                        "await student1.start_listening(ctx=ctx)\n",
                        "await student2.start_listening(ctx=ctx)\n",
                        "\n",
                        "# Teacher starts the conversation by posting a message to the pool\n",
                        "_ = await teacher.run(\"start\", ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "e845d2d2",
                  "metadata": {},
                  "source": [
                        "# Custom API providers and HTTP clients"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": 8,
                  "id": "94146e17",
                  "metadata": {},
                  "outputs": [
                        {
                              "name": "stdout",
                              "output_type": "stream",
                              "text": [
                                    "\u001b[32m\n",
                                    "[agent: chatbot | role: user | run: aae622_chatbot]\n",
                                    "Output a list of 3 integers from 0 to 10 as a python array, no talking\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "[agent: chatbot | role: assistant | run: aae622_chatbot]\n",
                                    "```python\n",
                                    "[7, 2, 9]\n",
                                    "```\u001b[0m\n",
                                    "\u001b[94m\n",
                                    "------------------------------------\n",
                                    "I/O/(R)/(C) tokens: 26/122\u001b[0m\n",
                                    "\n",
                                    "<Response>\n",
                                    "[7, 2, 9]\n"
                              ]
                        }
                  ],
                  "source": [
                        "custom_provider = APIProvider(\n",
                        "    name=\"openrouter\",\n",
                        "    base_url=\"https://openrouter.ai/api/v1\",\n",
                        "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
                        ")\n",
                        "\n",
                        "http_client = httpx.AsyncClient(\n",
                        "    timeout=httpx.Timeout(10),\n",
                        "    limits=httpx.Limits(max_connections=10),\n",
                        ")\n",
                        "\n",
                        "chatbot = LLMAgent[None, list[int], None](\n",
                        "    name=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"deepseek/deepseek-r1-0528\",\n",
                        "        api_provider=custom_provider,\n",
                        "        async_http_client=http_client,\n",
                        "    ),\n",
                        ")\n",
                        "\n",
                        "\n",
                        "ctx = RunContext[None](print_messages=True)\n",
                        "out = await chatbot.run(\n",
                        "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
                        "    ctx=ctx,\n",
                        ")\n",
                        "print_single_output(out)"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": ".venv",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.11.9"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 5
}
