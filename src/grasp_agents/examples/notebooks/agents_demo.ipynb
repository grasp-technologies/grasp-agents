{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7f54f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "from pydantic import Field, BaseModel\n",
    "import httpx\n",
    "\n",
    "from grasp_agents import (\n",
    "    BaseTool,\n",
    "    LLMAgent,\n",
    "    RunContext,\n",
    "    ImageData,\n",
    "    Printer,\n",
    "    print_event_stream,\n",
    "    ParallelProcessor,\n",
    ")\n",
    "from grasp_agents.runner import Runner\n",
    "from grasp_agents.typing.events import ProcPacketOutEvent\n",
    "from grasp_agents.openai import OpenAILLM, OpenAILLMSettings\n",
    "from grasp_agents.litellm import LiteLLM, LiteLLMSettings\n",
    "from grasp_agents.workflow.sequential_workflow import SequentialWorkflow\n",
    "from grasp_agents.cloud_llm import APIProvider\n",
    "from grasp_agents.rate_limiting import RateLimiter\n",
    "\n",
    "from grasp_agents.telemetry.traceloop import init_traceloop\n",
    "\n",
    "# Optional: enable LLM observability with Phoenix\n",
    "from grasp_agents.telemetry.phoenix import init_phoenix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b58f9f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGE_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353abb8b",
   "metadata": {},
   "source": [
    "Paths to images used in the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c0184c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_1_URL = \"https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\"\n",
    "IMG_2_PATH = PACKAGE_DIR / \"src/grasp_agents/examples/data/expr.jpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd56773",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "aaaa26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_single_output(out: Any) -> None:\n",
    "    print(f\"\\n<final answer>\\n{out.payloads[0]}\\n</final answer>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127705b",
   "metadata": {},
   "source": [
    "**[Optional] Observability with Arize Phoenix (deployed locally via Docker)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c99ece",
   "metadata": {},
   "source": [
    "Start Phoenix locally:\n",
    "```bash\n",
    "cd ./phoenix\n",
    "docker compose up -d  \n",
    "docker compose logs -f phoenix\n",
    "export PHOENIX_COLLECTOR_HTTP_ENDPOINT=http://localhost:6006/v1/traces # from docker-compose.yml\n",
    "export TELEMETRY_PROJECT_NAME_KEY=\"openinference.project.name\" # required by Phoenix\n",
    "```\n",
    "\n",
    "Open `http://localhost:6006/` (or the port you set in `docker-compose.yml`) in your browser to access the Phoenix UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1d6a1",
   "metadata": {},
   "source": [
    "Initialize telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7f2735a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "# Use Traceloop to produce spans (without sending them anywhere yet)\n",
    "init_traceloop(project_name=\"agents-demo\")\n",
    "\n",
    "# Use Phoenix as the backend and UI for telemetry\n",
    "# Alternatively, any OpenTelemetry-compatible backend can be used instead\n",
    "init_phoenix(batch=False, use_litellm_instr=True, use_llm_provider_instr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c502f9",
   "metadata": {},
   "source": [
    "## Simple generation with validated outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496af79a",
   "metadata": {},
   "source": [
    "Output type validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3fabce14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m10:45:32 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:32 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:32 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:32 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n"
     ]
    }
   ],
   "source": [
    "# list[int] is the output type used to validate the output\n",
    "chatbot = LLMAgent[None, list[int], None](\n",
    "    name=\"chatbot\",\n",
    "    llm=LiteLLM(\n",
    "        model_name=\"gpt-4o-mini\",\n",
    "        llm_settings=LiteLLMSettings(logprobs=True),\n",
    "        max_response_retries=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# This initialises printer and usage tracker\n",
    "ctx = RunContext[None](printer=Printer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "862d2b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [f8fbcc_chatbot]\n",
      "<input>\n",
      "Output a list of 3 integers from 0 to 10 as a python array, no talking\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [f8fbcc_chatbot]\n",
      "<response>\n",
      "```python\n",
      "[3, 7, 1]\n",
      "```\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 30/13/-/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "[3, 7, 1]\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "# Code block delimiters are stripped from the output\n",
    "out = await chatbot.run(\n",
    "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
    "    ctx=ctx,\n",
    ")\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4ae1a0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatbot': Usage(input_tokens=30, output_tokens=13, reasoning_tokens=0, cached_tokens=0, cost=1.23e-05)}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.usage_tracker.usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ceb7b3",
   "metadata": {},
   "source": [
    "Completion data (e.g. log probs) per agent can be accessed via RunContext:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f3806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctx.completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6611c",
   "metadata": {},
   "source": [
    "Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fd3e566d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m10:45:38 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:38 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:38 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:38 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n"
     ]
    }
   ],
   "source": [
    "chatbot = LLMAgent[None, list[int], None](\n",
    "    name=\"chatbot\",\n",
    "    llm=LiteLLM(\n",
    "        model_name=\"claude-sonnet-4-20250514\",\n",
    "        llm_settings=LiteLLMSettings(reasoning_effort=None),\n",
    "    ),\n",
    "    stream_llm_responses=True,\n",
    ")\n",
    "ctx = RunContext[None](printer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "adf0d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "<chatbot> [bf2da7_chatbot]\n",
      "<input>\n",
      "Output a list of 30 integers from 0 to 10 as a python array. No code or talking.\n",
      "</input>\n",
      "\u001b[0m\u001b[94m\n",
      "<chatbot> [bf2da7_chatbot]\n",
      "\u001b[0m\u001b[94m<response>\n",
      "\u001b[0m\u001b[94m[\u001b[0m\u001b[94m7\u001b[0m\u001b[94m, 2\u001b[0m\u001b[94m, 9\u001b[0m\u001b[94m, 1, 5\u001b[0m\u001b[94m, 8, 3, \u001b[0m\u001b[94m6, 0\u001b[0m\u001b[94m, 4, 9\u001b[0m\u001b[94m, 2, 7, \u001b[0m\u001b[94m5, 1\u001b[0m\u001b[94m, 8\u001b[0m\u001b[94m, 6\u001b[0m\u001b[94m, 3, 10\u001b[0m\u001b[94m, 4, 0, \u001b[0m\u001b[94m9, 7, 2\u001b[0m\u001b[94m, 5\u001b[0m\u001b[94m, 8, 1\u001b[0m\u001b[94m, 6, 4\u001b[0m\u001b[94m, 3]\u001b[0m\u001b[94m\n",
      "</response>\n",
      "\u001b[0m\u001b[94m\n",
      "<chatbot> [bf2da7_chatbot]\n",
      "<processor output>\n",
      "[\n",
      "  7,\n",
      "  2,\n",
      "  9,\n",
      "  1,\n",
      "  5,\n",
      "  8,\n",
      "  3,\n",
      "  6,\n",
      "  0,\n",
      "  4,\n",
      "  9,\n",
      "  2,\n",
      "  7,\n",
      "  5,\n",
      "  1,\n",
      "  8,\n",
      "  6,\n",
      "  3,\n",
      "  10,\n",
      "  4,\n",
      "  0,\n",
      "  9,\n",
      "  7,\n",
      "  2,\n",
      "  5,\n",
      "  8,\n",
      "  1,\n",
      "  6,\n",
      "  4,\n",
      "  3\n",
      "]\n",
      "</processor output>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "async for event in print_event_stream(\n",
    "    chatbot.run_stream(\n",
    "        \"Output a list of 30 integers from 0 to 10 as a python array. \"\n",
    "        \"No code or talking.\",\n",
    "        ctx=ctx,\n",
    "    )\n",
    "):\n",
    "    if isinstance(event, ProcPacketOutEvent):\n",
    "        out = event.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b2ef3a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chatbot': Usage(input_tokens=33, output_tokens=93, reasoning_tokens=0, cached_tokens=0, cost=0.0014939999999999999)}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.usage_tracker.usages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32b532",
   "metadata": {},
   "source": [
    "Output type validation with structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fbab149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m10:45:47 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:47 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:47 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:47 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n"
     ]
    }
   ],
   "source": [
    "# Some providers (e.g. `openai` and `gemini`) support structured outputs.\n",
    "# With the OpenAI API, this will require a Pydantic model to validate the output.\n",
    "\n",
    "from enum import StrEnum\n",
    "\n",
    "\n",
    "class Selector(StrEnum):\n",
    "    A = \"A\"\n",
    "    B = \"B\"\n",
    "\n",
    "\n",
    "class Response(BaseModel):\n",
    "    result: list[int] = Field(..., description=\"3 random integers\")\n",
    "    value: Selector = Field(..., description=\"Choose a value randomly\")\n",
    "\n",
    "\n",
    "chatbot = LLMAgent[None, Response, None](\n",
    "    name=\"chatbot\",\n",
    "    response_schema=Response,\n",
    "    llm=LiteLLM(\n",
    "        model_name=\"gemini/gemini-2.5-flash\",\n",
    "        llm_settings=LiteLLMSettings(),\n",
    "        apply_response_schema_via_provider=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# By default, response_schema is set to the output type of the agent (Response)\n",
    "# In some cases, you may want to set it to a different type, e.g. when using\n",
    "# custom output parsing.\n",
    "\n",
    "ctx = RunContext[None](printer=Printer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "320accf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [3c51f1_chatbot]\n",
      "<input>\n",
      "start\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [3c51f1_chatbot]\n",
      "<response>\n",
      "{\n",
      "  \"result\": [\n",
      "    14,\n",
      "    76,\n",
      "    3\n",
      "  ],\n",
      "  \"value\": \"A\"\n",
      "}\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 2/27/69/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "result=[14, 76, 3] value=<Selector.A: 'A'>\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run(\"start\", ctx=ctx)\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6893a1e",
   "metadata": {},
   "source": [
    "# Chat with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bbbb7c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m10:45:53 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:53 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:53 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:45:53 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n"
     ]
    }
   ],
   "source": [
    "chatbot = LLMAgent[None, str, None](\n",
    "    name=\"chatbot\",\n",
    "    llm=LiteLLM(\n",
    "        model_name=\"gemini/gemini-2.5-flash\",\n",
    "        llm_settings=LiteLLMSettings(reasoning_effort=\"disable\"),\n",
    "    ),\n",
    "    sys_prompt=\"You are a helpful assistant\",\n",
    ")\n",
    "ctx = RunContext[None](printer=Printer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f9140370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m<chatbot> [6d337b_chatbot]\n",
      "<system>\n",
      "You are a helpful assistant\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<chatbot> [6d337b_chatbot]\n",
      "<input>\n",
      "Where are you headed, stranger?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [6d337b_chatbot]\n",
      "<response>\n",
      "I am a large language model, trained by Google.\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 13/11/-/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "I am a large language model, trained by Google.\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run(\"Where are you headed, stranger?\", ctx=ctx)\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f883494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [174b16_chatbot]\n",
      "<input>\n",
      "What did you just say, exactly?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [174b16_chatbot]\n",
      "<response>\n",
      "I said, \"I am a large language model, trained by Google.\"\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 34/15/-/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "I said, \"I am a large language model, trained by Google.\"\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run(\"What did you just say, exactly?\", ctx=ctx)\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c9a2d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [15292b_chatbot]\n",
      "<input>\n",
      "What's in this image?\n",
      "<ENCODED_IMAGE>\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [15292b_chatbot]\n",
      "<response>\n",
      "The image displays a mathematical expression: **7 * (5 + 15) / (2 * 5) - 3**.\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 316/28/-/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "The image displays a mathematical expression: **7 * (5 + 15) / (2 * 5) - 3**.\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run(\n",
    "    [\"What's in this image?\", ImageData.from_path(IMG_2_PATH)], ctx=ctx\n",
    ")\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a3f291ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [8b5a4c_chatbot]\n",
      "<input>\n",
      "Do the calculation\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [8b5a4c_chatbot]\n",
      "<response>\n",
      "Let's break down the calculation step by step, following the order of operations (PEMDAS/BODMAS):\n",
      "\n",
      "1.  **Parentheses/Brackets:**\n",
      "    *   (5 + 15) = 20\n",
      "    *   (2 * 5) = 10\n",
      "\n",
      "2.  **Substitute these back into the expression:**\n",
      "    7 * 20 / 10 - 3\n",
      "\n",
      "3.  **Multiplication and Division (from left to right):**\n",
      "    *   7 * 20 = 140\n",
      "    *   140 / 10 = 14\n",
      "\n",
      "4.  **Substitute this back into the expression:**\n",
      "    14 - 3\n",
      "\n",
      "5.  **Subtraction:**\n",
      "    *   14 - 3 = 11\n",
      "\n",
      "So, the result of the calculation is **11**.\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 349/187/-/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "Let's break down the calculation step by step, following the order of operations (PEMDAS/BODMAS):\n",
      "\n",
      "1.  **Parentheses/Brackets:**\n",
      "    *   (5 + 15) = 20\n",
      "    *   (2 * 5) = 10\n",
      "\n",
      "2.  **Substitute these back into the expression:**\n",
      "    7 * 20 / 10 - 3\n",
      "\n",
      "3.  **Multiplication and Division (from left to right):**\n",
      "    *   7 * 20 = 140\n",
      "    *   140 / 10 = 14\n",
      "\n",
      "4.  **Substitute this back into the expression:**\n",
      "    14 - 3\n",
      "\n",
      "5.  **Subtraction:**\n",
      "    *   14 - 3 = 11\n",
      "\n",
      "So, the result of the calculation is **11**.\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run(\"Do the calculation\", ctx=ctx)\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a34a664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [faa8ff_chatbot]\n",
      "<input>\n",
      "Try another one\n",
      "https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [faa8ff_chatbot]\n",
      "<response>\n",
      "This image presents an arithmetic expression with given variable values.\n",
      "\n",
      "**Arithmetic Expression:**\n",
      "Z = a + b - (a * c)\n",
      "\n",
      "**Given values:**\n",
      "a = 2\n",
      "b = 3\n",
      "c = 4\n",
      "\n",
      "Let's calculate the value of Z:\n",
      "\n",
      "1.  **Substitute the values into the expression:**\n",
      "    Z = 2 + 3 - (2 * 4)\n",
      "\n",
      "2.  **Perform the operation inside the parentheses first:**\n",
      "    (2 * 4) = 8\n",
      "\n",
      "3.  **Substitute the result back into the expression:**\n",
      "    Z = 2 + 3 - 8\n",
      "\n",
      "4.  **Perform addition and subtraction from left to right:**\n",
      "    *   2 + 3 = 5\n",
      "    *   5 - 8 = -3\n",
      "\n",
      "Therefore, Z = **-3**.\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 799/180/-/-\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "This image presents an arithmetic expression with given variable values.\n",
      "\n",
      "**Arithmetic Expression:**\n",
      "Z = a + b - (a * c)\n",
      "\n",
      "**Given values:**\n",
      "a = 2\n",
      "b = 3\n",
      "c = 4\n",
      "\n",
      "Let's calculate the value of Z:\n",
      "\n",
      "1.  **Substitute the values into the expression:**\n",
      "    Z = 2 + 3 - (2 * 4)\n",
      "\n",
      "2.  **Perform the operation inside the parentheses first:**\n",
      "    (2 * 4) = 8\n",
      "\n",
      "3.  **Substitute the result back into the expression:**\n",
      "    Z = 2 + 3 - 8\n",
      "\n",
      "4.  **Perform addition and subtraction from left to right:**\n",
      "    *   2 + 3 = 5\n",
      "    *   5 - 8 = -3\n",
      "\n",
      "Therefore, Z = **-3**.\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run([\"Try another one\", ImageData.from_url(IMG_1_URL)], ctx=ctx)\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "468bef91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m<chatbot> [f8a07b_chatbot]\n",
      "<input>\n",
      "What was my first question, exactly?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<chatbot> [f8a07b_chatbot]\n",
      "<response>\n",
      "Your first question was: \"Where are you headed, stranger?\"\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 224/13/-/765\n",
      "\n",
      "\u001b[0m\n",
      "<final answer>\n",
      "Your first question was: \"Where are you headed, stranger?\"\n",
      "</final answer>\n"
     ]
    }
   ],
   "source": [
    "out = await chatbot.run(\"What was my first question, exactly?\", ctx=ctx)\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "737bb8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=1735, output_tokens=434, reasoning_tokens=None, cached_tokens=765, cost=0.0011640500000000002)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx.usage_tracker.total_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573afa4e",
   "metadata": {},
   "source": [
    "# Parallel runs with retries and rate limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e943daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m10:46:12 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:46:12 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:46:12 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:46:12 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n"
     ]
    }
   ],
   "source": [
    "# Make the LLM generate text instead of integers occasionally\n",
    "# to emphasise the need for retries\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "You are a bad math student who always adds number {added_num} to the correct result of the operation. \n",
    "Output a single integer or its name, e.g. 'three' or '3'.\n",
    "\"\"\"\n",
    "\n",
    "in_prompt = \"What is the square of {num}?\"\n",
    "\n",
    "\n",
    "class RunArgs(BaseModel):\n",
    "    added_num: int\n",
    "\n",
    "\n",
    "class InputArgs(BaseModel):\n",
    "    num: int\n",
    "\n",
    "\n",
    "# Specifying int as the output type means that the agent will\n",
    "# validate the output against this type.\n",
    "\n",
    "student = LLMAgent[InputArgs, int, RunArgs](\n",
    "    name=\"student\",\n",
    "    llm=LiteLLM(\n",
    "        model_name=\"gpt-4.1\",\n",
    "        llm_settings=LiteLLMSettings(temperature=1.8),\n",
    "        # This rate limit will be applied to parallel runs of the agent\n",
    "        rate_limiter=RateLimiter(rpm=100),\n",
    "    ),\n",
    "    sys_prompt=sys_prompt,\n",
    "    in_prompt=in_prompt,\n",
    "    reset_memory_on_run=True,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "\n",
    "@student.add_system_prompt_builder\n",
    "def system_prompt_builder(ctx: RunContext[RunArgs], **kwargs: Any) -> str:\n",
    "    return student.sys_prompt.format(added_num=ctx.state.added_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "35c18893",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_args = [InputArgs(num=i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7266ea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m<student> [60e2df_student_par/0]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/0]\n",
      "<input>\n",
      "What is the square of 0?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/1]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/1]\n",
      "<input>\n",
      "What is the square of 1?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/2]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/2]\n",
      "<input>\n",
      "What is the square of 2?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/3]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/3]\n",
      "<input>\n",
      "What is the square of 3?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/4]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/4]\n",
      "<input>\n",
      "What is the square of 4?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/5]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/5]\n",
      "<input>\n",
      "What is the square of 5?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/6]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/6]\n",
      "<input>\n",
      "What is the square of 6?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/7]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/7]\n",
      "<input>\n",
      "What is the square of 7?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/8]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/8]\n",
      "<input>\n",
      "What is the square of 8?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[35m<student> [60e2df_student_par/9]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\n",
      "\u001b[0m\u001b[32m<student> [60e2df_student_par/9]\n",
      "<input>\n",
      "What is the square of 9?\n",
      "</input>\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/0]\n",
      "<response>\n",
      "5\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/1]\n",
      "<response>\n",
      "6\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/2]\n",
      "<response>\n",
      "9\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/3]\n",
      "<response>\n",
      "14\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/4]\n",
      "<response>\n",
      "21\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/5]\n",
      "<response>\n",
      "30\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/7]\n",
      "<response>\n",
      "54\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/6]\n",
      "<response>\n",
      "41\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/8]\n",
      "<response>\n",
      "69\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\u001b[94m<student> [60e2df_student_par/9]\n",
      "<response>\n",
      "86\n",
      "</response>\n",
      "\n",
      "------------------------------------\n",
      "I/O/R/C tokens: 61/1/-/-\n",
      "\n",
      "\u001b[0m\n",
      "5\n",
      "6\n",
      "9\n",
      "14\n",
      "21\n",
      "30\n",
      "41\n",
      "54\n",
      "69\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "ctx = RunContext[RunArgs](state=RunArgs(added_num=5), printer=Printer())\n",
    "\n",
    "# Wrap the agent in a ParallelProcessor to run it in parallel\n",
    "out = await ParallelProcessor(student).run(in_args=in_args, ctx=ctx)\n",
    "\n",
    "print()\n",
    "print(*[p for p in out.payloads], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "96634da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "<student> [04456e_student_par/0]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/0]\n",
      "<input>\n",
      "What is the square of 0?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/1]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/1]\n",
      "<input>\n",
      "What is the square of 1?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/2]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/2]\n",
      "<input>\n",
      "What is the square of 2?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/3]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/3]\n",
      "<input>\n",
      "What is the square of 3?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/4]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/4]\n",
      "<input>\n",
      "What is the square of 4?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/5]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/5]\n",
      "<input>\n",
      "What is the square of 5?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/6]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/6]\n",
      "<input>\n",
      "What is the square of 6?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/7]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/7]\n",
      "<input>\n",
      "What is the square of 7?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/8]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/8]\n",
      "<input>\n",
      "What is the square of 8?\n",
      "</input>\n",
      "\u001b[0m\u001b[35m\n",
      "<student> [04456e_student_par/9]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/9]\n",
      "<input>\n",
      "What is the square of 9?\n",
      "</input>\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both ast.literal_eval and json.loads failed to parse the following JSON/Python string:\n",
      "Six\n",
      "Processor run failed [proc_name=student; call_id=04456e_student_par/1] -> retrying (attempt 1):\n",
      "Failed to validate LLM response:\n",
      "Six\n",
      "Expected type: <class 'int'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "<student> [04456e_student_par/1]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/1]\n",
      "<input>\n",
      "What is the square of 1?\n",
      "</input>\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both ast.literal_eval and json.loads failed to parse the following JSON/Python string:\n",
      "Nine\n",
      "Processor run failed [proc_name=student; call_id=04456e_student_par/2] -> retrying (attempt 1):\n",
      "Failed to validate LLM response:\n",
      "Nine\n",
      "Expected type: <class 'int'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "<student> [04456e_student_par/2]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/2]\n",
      "<input>\n",
      "What is the square of 2?\n",
      "</input>\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both ast.literal_eval and json.loads failed to parse the following JSON/Python string:\n",
      "Thirty\t\n",
      "Processor run failed [proc_name=student; call_id=04456e_student_par/5] -> retrying (attempt 1):\n",
      "Failed to validate LLM response:\n",
      "Thirty\t\n",
      "Expected type: <class 'int'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "<student> [04456e_student_par/5]\n",
      "<system>\n",
      "You are a bad math student who always adds number 5 to the correct result of the operation. \n",
      "Output a single integer or its name, e.g. 'three' or '3'.\n",
      "</system>\n",
      "\u001b[0m\u001b[32m\n",
      "<student> [04456e_student_par/5]\n",
      "<input>\n",
      "What is the square of 5?\n",
      "</input>\n",
      "\u001b[0m\u001b[94m\n",
      "<student_par> [04456e_student_par]\n",
      "<processor output>\n",
      "5\n",
      "6\n",
      "9\n",
      "14\n",
      "21\n",
      "30\n",
      "41\n",
      "54\n",
      "69\n",
      "86\n",
      "</processor output>\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "ctx = RunContext[RunArgs](state=RunArgs(added_num=5))\n",
    "\n",
    "# Do not stream granular LLM events here\n",
    "stream = ParallelProcessor(student).run_stream(in_args=in_args, ctx=ctx)\n",
    "async for event in print_event_stream(stream):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8423f",
   "metadata": {},
   "source": [
    "# Reasoning agent loop with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "34206828",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt_react = \"\"\"\n",
    "Your task is to suggest an exciting stats problem to the student. \n",
    "You should first ask the student about their education, interests, and preferences, then suggest a problem tailored specifically to them. \n",
    "\n",
    "# Instructions\n",
    "* Use the provided tool to ask questions.\n",
    "* Ask questions one by one.\n",
    "* The problem must have all the necessary data.\n",
    "* Use the final answer tool to provide the problem.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3f5a2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool input must be a Pydantic model to infer the JSON schema used by the LLM APIs\n",
    "class TeacherQuestion(BaseModel):\n",
    "    question: str\n",
    "\n",
    "\n",
    "StudentReply = str\n",
    "\n",
    "\n",
    "ask_student_tool_description = \"\"\"\n",
    "\"Ask the student a question and get their reply.\"\n",
    "\n",
    "Args:\n",
    "    question: str\n",
    "        The question to ask the student.\n",
    "Returns:\n",
    "    reply: str\n",
    "        The student's reply to the question.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AskStudentTool(BaseTool[TeacherQuestion, StudentReply, Any]):\n",
    "    name: str = \"ask_student\"\n",
    "    description: str = ask_student_tool_description\n",
    "\n",
    "    async def run(self, inp: TeacherQuestion, **kwargs: Any) -> StudentReply:\n",
    "        return input(inp.question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6a8180f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m10:47:03 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:47:03 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:47:03 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n",
      "\u001b[92m10:47:03 - LiteLLM:WARNING\u001b[0m: logging_callback_manager.py:138 - Cannot add callback - would exceed MAX_CALLBACKS limit of 30. Current callbacks: 30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LLMAgent.__init__() got an unexpected keyword argument 'tracing_exclude_input_fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mProblem\u001b[39;00m(BaseModel):\n\u001b[1;32m      2\u001b[0m     problem: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m----> 5\u001b[0m teacher \u001b[38;5;241m=\u001b[39m \u001b[43mLLMAgent\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mProblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mteacher\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLiteLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-sonnet-4-5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLiteLLMSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mAskStudentTool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# react_mode=True, # use with non-reasoning models to enforce preamble/tool/response structure\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_answer_as_tool_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43msys_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys_prompt_react\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_llm_responses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_exclude_input_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mctx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/uv/python/cpython-3.11.9-macos-aarch64-none/lib/python3.11/typing.py:1289\u001b[0m, in \u001b[0;36m_BaseGenericAlias.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inst:\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be instantiated; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1288\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__origin__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1289\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__origin__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1291\u001b[0m     result\u001b[38;5;241m.\u001b[39m__orig_class__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: LLMAgent.__init__() got an unexpected keyword argument 'tracing_exclude_input_fields'"
     ]
    }
   ],
   "source": [
    "class Problem(BaseModel):\n",
    "    problem: str\n",
    "\n",
    "\n",
    "teacher = LLMAgent[None, Problem, None](\n",
    "    name=\"teacher\",\n",
    "    llm=LiteLLM(\n",
    "        model_name=\"claude-sonnet-4-5\",\n",
    "        llm_settings=LiteLLMSettings(reasoning_effort=\"low\"),\n",
    "    ),\n",
    "    tools=[AskStudentTool()],\n",
    "    # react_mode=True, # use with non-reasoning models to enforce preamble/tool/response structure\n",
    "    final_answer_as_tool_call=True,\n",
    "    sys_prompt=sys_prompt_react,\n",
    "    stream_llm_responses=True,\n",
    "    tracing_exclude_input_fields={\"ctx\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b058453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = RunContext[None]()\n",
    "\n",
    "events = []\n",
    "problem: Problem\n",
    "async for event in print_event_stream(teacher.run_stream(\"start\", ctx=ctx)):\n",
    "    if isinstance(event, ProcPacketOutEvent):\n",
    "        problem = event.data.payloads[0]\n",
    "    events.append(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467329cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d54e9b",
   "metadata": {},
   "source": [
    "# Sequential workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac335deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input arguments are passed to the agent dynamically (e.g. by other agents)\n",
    "from grasp_agents.typing.content import Content\n",
    "\n",
    "\n",
    "# Global state is used to store data that is shared between runs of the agent.\n",
    "class State(BaseModel):\n",
    "    b: int\n",
    "    c: int\n",
    "\n",
    "\n",
    "class AddInputArgs(BaseModel):\n",
    "    a: int = Field(..., description=\"First number to add.\")\n",
    "\n",
    "\n",
    "class AddResponse(BaseModel):\n",
    "    a_plus_b: int\n",
    "\n",
    "\n",
    "add_in_prompt = \"Add {a} and {b}. Your only output is the resulting number.\"\n",
    "\n",
    "\n",
    "add_agent = LLMAgent[AddInputArgs, AddResponse, State](\n",
    "    name=\"add_agent\",\n",
    "    llm=LiteLLM(model_name=\"gpt-4.1\"),\n",
    "    in_prompt=add_in_prompt,\n",
    "    # Reset message history to system prompt (if provided) before each run\n",
    "    reset_memory_on_run=True,\n",
    "    stream_llm_responses=True,\n",
    ")\n",
    "\n",
    "\n",
    "@add_agent.add_input_content_builder\n",
    "def build_input_content_impl(\n",
    "    in_args: AddInputArgs, ctx: RunContext[State], call_id: str\n",
    ") -> Content:\n",
    "    return Content.from_formatted_prompt(\n",
    "        add_agent.in_prompt, a=in_args.a, b=ctx.state.b\n",
    "    )\n",
    "\n",
    "\n",
    "@add_agent.add_output_parser\n",
    "def parse_output_impl(\n",
    "    final_answer: str,\n",
    "    *,\n",
    "    in_args: AddInputArgs | None = None,\n",
    "    ctx: RunContext[State],\n",
    "    call_id: str,\n",
    ") -> AddResponse:\n",
    "    return AddResponse(a_plus_b=int(final_answer.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyResponse(BaseModel):\n",
    "    c_a_plus_b: int\n",
    "\n",
    "\n",
    "multiply_in_prompt = (\n",
    "    \"Multiply {a_plus_b} by {c}. Your only output is the resulting number.\"\n",
    ")\n",
    "\n",
    "multiply_agent = LLMAgent[AddResponse, MultiplyResponse, State](\n",
    "    name=\"multiply_agent\",\n",
    "    llm=LiteLLM(model_name=\"gpt-4.1\"),\n",
    "    in_prompt=multiply_in_prompt,\n",
    "    reset_memory_on_run=True,\n",
    "    stream_llm_responses=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Need a custom input content maker to use the global state\n",
    "@multiply_agent.add_input_content_builder\n",
    "def build_input_content_impl(\n",
    "    in_args: AddResponse, ctx: RunContext[State], call_id: str\n",
    ") -> Content:\n",
    "    return Content.from_formatted_prompt(\n",
    "        multiply_agent.in_prompt, a_plus_b=in_args.a_plus_b, c=ctx.state.c\n",
    "    )\n",
    "\n",
    "\n",
    "@multiply_agent.add_output_parser\n",
    "def parse_output_impl(\n",
    "    final_answer: str,\n",
    "    *,\n",
    "    in_args: AddResponse | None = None,\n",
    "    ctx: RunContext[State],\n",
    "    call_id: str,\n",
    ") -> MultiplyResponse:\n",
    "    return MultiplyResponse(c_a_plus_b=int(final_answer.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_agent = SequentialWorkflow[AddInputArgs, MultiplyResponse, State](\n",
    "    name=\"seq_agent\", subprocs=[add_agent, multiply_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac65585",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = State(b=3, c=6)\n",
    "ctx = RunContext[State](state=state, printer=Printer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = await seq_agent.run(in_args=AddInputArgs(a=2), ctx=ctx)\n",
    "\n",
    "# out = await ParallelProcessor(seq_agent).run(\n",
    "#     in_args=[AddInputArgs(a=2), AddInputArgs(a=3)], ctx=ctx\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cffd87",
   "metadata": {},
   "source": [
    "# Agents as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bf21c6",
   "metadata": {},
   "source": [
    "When agents are used as tools, their `in_args` become the tool inputs.\n",
    "\n",
    "This is how one can implement a manager + helpers architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33230157",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tool = seq_agent.as_tool(\n",
    "    tool_name=\"seq_agent_tool\",\n",
    "    tool_description=(\n",
    "        \"A sequential agent that adds 3 to a given integer, \"\n",
    "        \"then multiplies the result by 5.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb7a87",
   "metadata": {},
   "source": [
    "The JSON schema of `in_args` is preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62072904",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_tool.in_type.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4efa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "await seq_tool(a=15, ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc51afd9",
   "metadata": {},
   "source": [
    "Stream from the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dba200",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = State(b=3, c=6)\n",
    "ctx = RunContext[State](state=state)\n",
    "\n",
    "seq_agent = SequentialWorkflow[AddInputArgs, MultiplyResponse, State](\n",
    "    name=\"seq_agent\", subprocs=[add_agent, multiply_agent]\n",
    ")\n",
    "seq_tool = seq_agent.as_tool(\n",
    "    tool_name=\"seq_agent_tool\",\n",
    "    tool_description=(\n",
    "        \"A sequential agent that adds 3 to a given integer, \"\n",
    "        \"then multiplies the result by 5.\"\n",
    "    ),\n",
    ")\n",
    "stream = seq_tool.run_stream(AddInputArgs(a=15), ctx=ctx)\n",
    "\n",
    "async for event in print_event_stream(stream):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5b69b0",
   "metadata": {},
   "source": [
    "# Teacher / students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1b303",
   "metadata": {},
   "source": [
    "A more advanced example of multi-agent debate, where agents communicate using the actor model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29915a9",
   "metadata": {},
   "source": [
    "Communication schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc61e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "TeacherRecipient = Literal[\"*END*\", \"teacher\", \"student1\", \"student2\"]\n",
    "\n",
    "\n",
    "# Teacher can choose which students to send the message to\n",
    "class TeacherExplanation(BaseModel):\n",
    "    explanation: str\n",
    "    selected_recipients: Sequence[TeacherRecipient] = Field(\n",
    "        default_factory=list[TeacherRecipient],\n",
    "        description=\"Recipients selected by the teacher.\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Students can only ask questions to the teacher\n",
    "class StudentQuestion(BaseModel):\n",
    "    question: str = Field(\n",
    "        ...,\n",
    "        description=\"The question to ask the teacher.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29748a",
   "metadata": {},
   "source": [
    "#### Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27436f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_sys_prompt = \"\"\"\n",
    "You are a teacher explaining quantum gravity to a 2-year old baby (named 'student1') and a 30-year old graphic designer (named student2). \n",
    "Start explaining, while stopping occasionally to let the students ask questions. \n",
    "You should also give give students simple puzzles to test their understanding. \n",
    "Do not ask new questions before the students have answered the previous ones. \n",
    "To indicate to whom you are addressing your message, you must specify the recipients as a list of selected student names. \n",
    "When students have no more questions, finish the conversation with a SINGLE message with a SINGLE recipient called *END*. \n",
    "Do not produce multiple \"thanks\" or \"goodbye\" messages, just a single one.\n",
    "\"\"\"\n",
    "\n",
    "teacher = LLMAgent[StudentQuestion, TeacherExplanation, None](\n",
    "    name=\"teacher\",\n",
    "    llm=LiteLLM(model_name=\"gpt-4o\", apply_response_schema_via_provider=True),\n",
    "    sys_prompt=teacher_sys_prompt,\n",
    "    # need to specify allowed recipients to choose from\n",
    "    recipients=[\"*END*\", \"student1\", \"student2\"],\n",
    ")\n",
    "\n",
    "\n",
    "@teacher.add_recipient_selector\n",
    "def select_recipients_impl(\n",
    "    output: TeacherExplanation, **kwargs: Any\n",
    ") -> Sequence[TeacherRecipient] | None:\n",
    "    return output.selected_recipients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7af0c9",
   "metadata": {},
   "source": [
    "#### Students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df642fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_sys_prompts = [\n",
    "    \"\"\"\n",
    "You are a 4-year old child trying to make sense of physics. \n",
    "Your name is <student1>.\n",
    "Talk to the teacher to understand the topic.\n",
    "There is also another student in the class, a 30 year old graphic designer. \n",
    "You talk to the teacher only.\n",
    "\"\"\",\n",
    "    \"\"\"\n",
    "You are a 30-year old experienced graphic designer curious about physics. \n",
    "Your name is <student2>.\n",
    "Ask questions to the teacher until you understand the topic. \n",
    "Attempt to answer the teacher's questions, but if you don't understand,\n",
    "ask for clarification. \n",
    "There is also another student in the class, a 4-year old child.\n",
    "You talk to the teacher only.\n",
    "\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "def make_student_agent(name: str, sys_prompt: str):\n",
    "    student = LLMAgent[TeacherExplanation, StudentQuestion, None](\n",
    "        name=name,\n",
    "        llm=LiteLLM(model_name=\"gpt-4o\", apply_response_schema_via_provider=True),\n",
    "        sys_prompt=sys_prompt,\n",
    "        recipients=[\"teacher\"],\n",
    "    )\n",
    "\n",
    "    @student.add_output_parser\n",
    "    def parse_output_impl(final_answer: str, **kwargs: Any) -> StudentQuestion:\n",
    "        return StudentQuestion(question=f\"<{name}>: \" + str(final_answer))\n",
    "\n",
    "    return student\n",
    "\n",
    "\n",
    "student1 = make_student_agent(\"student1\", student_sys_prompts[0])\n",
    "student2 = make_student_agent(\"student2\", student_sys_prompts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1687f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = RunContext[None](printer=Printer(color_by=\"agent\"))\n",
    "runner = Runner(entry_proc=teacher, procs=[teacher, student1, student2], ctx=ctx)\n",
    "final_result = await runner.run(\"start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e7ee5",
   "metadata": {},
   "source": [
    "Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6fedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# runner = Runner(\n",
    "#     entry_proc=teacher, procs=[teacher, student1, student2], ctx=RunContext[None]()\n",
    "# )\n",
    "# events = []\n",
    "# async for event in print_event_stream(\n",
    "#     runner.run_stream(chat_inputs=\"start\"), color_by=\"agent\"\n",
    "# ):\n",
    "#     events.append(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38663f9d",
   "metadata": {},
   "source": [
    "# Custom API providers and HTTP clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3e402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_provider = APIProvider(\n",
    "    name=\"openrouter\",\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "http_client = httpx.AsyncClient(\n",
    "    timeout=httpx.Timeout(10),\n",
    "    limits=httpx.Limits(max_connections=10),\n",
    ")\n",
    "\n",
    "chatbot = LLMAgent[None, list[int], None](\n",
    "    name=\"chatbot\",\n",
    "    llm=OpenAILLM(\n",
    "        model_name=\"deepseek/deepseek-r1-0528\",\n",
    "        api_provider=custom_provider,\n",
    "        http_client=http_client,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "ctx = RunContext[None](printer=Printer())\n",
    "out = await chatbot.run(\n",
    "    \"Output a list of 3 integers from 0 to 10 as a python array, no talking\",\n",
    "    ctx=ctx,\n",
    ")\n",
    "print_single_output(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb828f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grasp-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
