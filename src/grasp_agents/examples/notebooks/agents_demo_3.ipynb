{
      "cells": [
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "b4798f40",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "%load_ext autoreload\n",
                        "%autoreload 2\n"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "e7bab540",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "from pathlib import Path\n",
                        "import re\n",
                        "from typing import Any\n",
                        "from pydantic import Field\n",
                        "\n",
                        "from grasp_agents.grasp_logging import setup_logging\n",
                        "from grasp_agents.agent_message_pool import (\n",
                        "    AgentMessagePool,\n",
                        ")\n",
                        "from grasp_agents.llm_agent import LLMAgent\n",
                        "from grasp_agents.openai.openai_llm import (\n",
                        "    OpenAILLM,\n",
                        "    OpenAILLMSettings,\n",
                        ")\n",
                        "from grasp_agents.typing.io import (\n",
                        "    AgentPayload,\n",
                        "    LLMPromptArgs,\n",
                        ")\n",
                        "from pydantic import BaseModel\n",
                        "from grasp_agents.typing.tool import BaseTool\n",
                        "from grasp_agents.run_context import RunContextWrapper, RunArgs\n",
                        "from grasp_agents.agent_message import AgentMessage\n",
                        "from grasp_agents.typing.content import ImageData\n",
                        "from grasp_agents.utils import get_timestamp\n",
                        "from grasp_agents.workflow.sequential_agent import SequentialWorkflowAgent\n",
                        "from grasp_agents.llm_agent_state import LLMAgentState"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "365844a1",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "PACKAGE_DIR = Path.cwd()\n",
                        "DATA_DIR = Path.cwd() / \"data/multiagent\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "a25cd25a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "LOGGING_DIR = DATA_DIR / \"logs\"\n",
                        "LOGGING_CFG_PATH = PACKAGE_DIR / \"configs/logging/default.yaml\"\n",
                        "setup_logging(\n",
                        "    LOGGING_DIR / f\"agents_demo_{get_timestamp()}.log\",\n",
                        "    LOGGING_CFG_PATH,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d0a377d1",
                  "metadata": {},
                  "source": [
                        "# Chat"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "c7ee012b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "IMG_1_URL = \"https://www.simplilearn.com/ice9/free_resources_article_thumb/Expressions_In_C_2.PNG\"\n",
                        "IMG_2_PATH = Path.cwd() / \"src/grasp_agents/examples/data/expr.jpeg\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "2647787f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class Response(AgentPayload):\n",
                        "    response: str\n",
                        "\n",
                        "\n",
                        "chatbot = LLMAgent[Any, Response, None](\n",
                        "    agent_id=\"chatbot\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"gpt-4.1\",\n",
                        "        llm_settings=OpenAILLMSettings(),\n",
                        "    ),\n",
                        "    sys_prompt=None,\n",
                        "    out_schema=Response,\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@chatbot.parse_output_handler\n",
                        "def output_handler(conversation, ctx, **kwargs) -> Response:\n",
                        "    return Response(response=conversation[-1].content)\n",
                        "\n",
                        "\n",
                        "# This initialises printer and usege tracker\n",
                        "ctx = RunContextWrapper(print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "d204005b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await chatbot.run(\"Where are you headed, stranger?\", ctx=ctx)\n",
                        "print(out.payloads[0].response)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "75a659b9",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await chatbot.run(\"What did you just say, exactly?\", ctx=ctx)\n",
                        "print(out.payloads[0].response)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "52b2da45",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await chatbot.run(\n",
                        "    [\"What's in this image?\", ImageData.from_path(IMG_2_PATH)], ctx=ctx\n",
                        ")\n",
                        "print(out.payloads[0].response)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "e441ca1e",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await chatbot.run(\"Go on\", ctx=ctx)\n",
                        "print(out.payloads[0].response)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "d0ab7eb2",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await chatbot.run([\"Try another one\", ImageData.from_url(IMG_1_URL)], ctx=ctx)\n",
                        "print(out.payloads[0].response)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "5f35439a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await chatbot.run(\"What was my first question, exactly?\", ctx=ctx)\n",
                        "print(out.payloads[0].response)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "fe068493",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "868cceb9",
                  "metadata": {},
                  "source": [
                        "# Structured outputs"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "50cd31c4",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "from enum import StrEnum\n",
                        "\n",
                        "\n",
                        "class Selector(StrEnum):\n",
                        "    S1 = \"S1\"\n",
                        "    S2 = \"S2\"\n",
                        "\n",
                        "\n",
                        "class Response(AgentPayload):\n",
                        "    a: int = Field(..., description=\"This integer must be equal to 1123\")\n",
                        "    b: bool = Field(..., description=\"This boolean must be equal to False\")\n",
                        "    s: Selector = Field(..., description=\"Choose a value randomly\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "8ccaa3a2",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Structured outputs are not supported via openrouter, but generated messages\n",
                        "# can still be validated against the provided schema (response_format)\n",
                        "\n",
                        "# In case structured outputs are not supported, we need to provide the output schema\n",
                        "# in the prompt. Otherwise the prompt can be empty in this example.\n",
                        "\n",
                        "# inp_prompt = \"\"\"\n",
                        "# Output a plain JSON string (no formatting) that contains the following fields:\n",
                        "# - a: an integer that must be equal to 1123\n",
                        "# - b: a boolean that must be equal to False\n",
                        "# - s: a string that must be either \"S1\" or \"S2\"\n",
                        "\n",
                        "# {{\n",
                        "#   \"a\": <integer>,\n",
                        "#   \"b\": <boolean>,\n",
                        "#   \"s\": <string>\n",
                        "# }}\n",
                        "# \"\"\"\n",
                        "\n",
                        "test_agent = LLMAgent[Any, Response, None](\n",
                        "    agent_id=\"test_agent\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"gemini-2.5-pro-preview-03-25\",\n",
                        "        api_provider=\"google_ai_studio\",\n",
                        "        # model_name=\"gpt-4.1\",\n",
                        "        # api_provider=\"openai\",\n",
                        "        # model_name=\"anthropic/claude-3.7-sonnet\",\n",
                        "        # api_provider=\"openrouter\",\n",
                        "        num_generation_retries=0,\n",
                        "        llm_settings=OpenAILLMSettings(temperature=0),\n",
                        "        response_format=Response,\n",
                        "    ),\n",
                        "    inp_prompt=\"\",\n",
                        "    out_schema=Response,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "e90caf1f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContextWrapper(print_messages=True)\n",
                        "out = await test_agent.run(ctx=ctx)\n",
                        "out.payloads[0]"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "32247af5",
                  "metadata": {},
                  "source": [
                        "# Simple batching"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "8ff9a28b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "sys_prompt = \"You are a bad math student who always adds number {added_num} to the correct result of the operation.\"\n",
                        "usr_prompt = \"What is the square of {num}?\"\n",
                        "\n",
                        "\n",
                        "class SystemArgs(LLMPromptArgs):\n",
                        "    added_num: int\n",
                        "\n",
                        "\n",
                        "class InputArgs(LLMPromptArgs):\n",
                        "    num: int\n",
                        "\n",
                        "\n",
                        "class Response(AgentPayload):\n",
                        "    response: str\n",
                        "\n",
                        "\n",
                        "student = LLMAgent[Any, Response, None](\n",
                        "    agent_id=\"student\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"gpt-4.1\",\n",
                        "        llm_settings=OpenAILLMSettings(),\n",
                        "        # rate_limiter_rpm=50,\n",
                        "    ),\n",
                        "    sys_prompt=sys_prompt,\n",
                        "    sys_args_schema=SystemArgs,\n",
                        "    inp_prompt=usr_prompt,\n",
                        "    usr_args_schema=InputArgs,\n",
                        "    out_schema=Response,\n",
                        "    set_state_strategy=\"keep\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@student.parse_output_handler\n",
                        "def output_handler(conversation, ctx, **kwargs) -> Response:\n",
                        "    return Response(response=conversation[-1].content)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ff403421",
                  "metadata": {},
                  "source": [
                        "#### One system prompt -> many user arguments"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "75d3664a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "run_args = RunArgs(\n",
                        "    sys=SystemArgs(added_num=1),\n",
                        "    usr=[InputArgs(num=i) for i in range(1, 10)],\n",
                        ")\n",
                        "\n",
                        "ctx = RunContextWrapper(run_args={\"student\": run_args}, print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "2ac96a56",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await student.run(ctx=ctx)\n",
                        "print(*[p.response for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "20dfa115",
                  "metadata": {},
                  "source": [
                        "#### Many back to one"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "888b8240",
                  "metadata": {},
                  "source": [
                        "Here, the single direct user input overrides the previous input prompt template"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "a1b9117f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await student.run(\n",
                        "    \"Who are you, dear stranger? What was your last chore?\", ctx=ctx\n",
                        ")\n",
                        "print(*[p.response for p in out.payloads], sep=\"\\n\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "ea5d2cc2",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx.usage_tracker.total_usage"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "a8b2df86",
                  "metadata": {},
                  "source": [
                        "# ReAct agent loop "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "cf879624",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "sys_prompt_react = \"\"\"\n",
                        "You are a gifted stats tutor. Your task is to suggest an exciting stats problem to the student. \n",
                        "You should first ask the student about their education, interests, and preferences, then suggest a problem tailored specifically to them. \n",
                        "\n",
                        "# Instructions\n",
                        "* Ask questions one by one.\n",
                        "* Provide your thinking before asking a question and after receiving a reply.\n",
                        "* Do not include your exact question as part of your thinking.\n",
                        "* The problem must have all the necessary data.\n",
                        "* The problem must be enclosed in <PROBLEM> tags.\n",
                        "\"\"\""
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "d8b5401f",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class TeacherQuestion(BaseModel):\n",
                        "    question: str\n",
                        "\n",
                        "\n",
                        "class StudentReply(BaseModel):\n",
                        "    reply: str\n",
                        "\n",
                        "\n",
                        "ask_student_tool_description = \"\"\"\n",
                        "\"Ask the student a question and get their reply.\"\n",
                        "\n",
                        "Args:\n",
                        "    question: str\n",
                        "        The question to ask the student.\n",
                        "Returns:\n",
                        "    {\"reply\": str}\n",
                        "        Dictionary containing the student's reply to the question.\n",
                        "\"\"\"\n",
                        "\n",
                        "\n",
                        "class AskStudentTool(BaseTool[TeacherQuestion, StudentReply, Any]):\n",
                        "    name: str = \"ask_student\"\n",
                        "    description: str = ask_student_tool_description\n",
                        "    in_schema: type[TeacherQuestion] = TeacherQuestion\n",
                        "    out_schema: type[StudentReply] = StudentReply\n",
                        "\n",
                        "    async def run(\n",
                        "        self, inp: BaseModel, ctx: RunContextWrapper[Any] | None = None\n",
                        "    ) -> StudentReply:\n",
                        "        reply = input(inp.question)\n",
                        "\n",
                        "        return StudentReply(reply=reply)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "dd35a6ac",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class Response(AgentPayload):\n",
                        "    problem: str\n",
                        "\n",
                        "\n",
                        "teacher = LLMAgent[Any, Response, None](\n",
                        "    agent_id=\"teacher\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"gpt-4.1\",\n",
                        "        api_provider=\"openai\",\n",
                        "        llm_settings=OpenAILLMSettings(temperature=0.5),\n",
                        "        # rate_limiter_rpm=50,\n",
                        "    ),\n",
                        "    tools=[AskStudentTool()],\n",
                        "    max_turns=20,\n",
                        "    react_mode=True,\n",
                        "    sys_prompt=sys_prompt_react,\n",
                        "    out_schema=Response,\n",
                        "    set_state_strategy=\"reset\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@teacher.tool_call_loop_exit_handler\n",
                        "def tool_call_loop_exit(conversation, ctx, **kwargs) -> None:\n",
                        "    message = conversation[-1].content\n",
                        "\n",
                        "    return re.search(r\"<PROBLEM>\", message)\n",
                        "\n",
                        "\n",
                        "@teacher.parse_output_handler\n",
                        "def parse_output(conversation, ctx, **kwargs) -> Response:\n",
                        "    return Response(problem=conversation[-1].content)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "b4a8e110",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContextWrapper(print_messages=True)"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "5bcf7b38",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await teacher.run(ctx=ctx)\n",
                        "print(out.payloads[0].problem)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "f1e6be13",
                  "metadata": {},
                  "source": [
                        "# Sequential workflow "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "829b6c96",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "add_inp_prompt = \"Add {a} and {b}. Your only output is the resulting number.\"\n",
                        "\n",
                        "\n",
                        "# Received arguments are passed to the agent dynamically\n",
                        "class AddReceivedArgs(AgentPayload):\n",
                        "    a: int = Field(..., description=\"First number to add.\")\n",
                        "\n",
                        "\n",
                        "# User arguments are passed to the agent statically via run_args\n",
                        "class AddUserArgs(LLMPromptArgs):\n",
                        "    b: int\n",
                        "\n",
                        "\n",
                        "class AddResponse(AgentPayload):\n",
                        "    result: int\n",
                        "\n",
                        "\n",
                        "add_agent = LLMAgent[AddReceivedArgs, AddResponse, None](\n",
                        "    agent_id=\"add_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"gpt-4.1\", llm_settings=OpenAILLMSettings()),\n",
                        "    rcv_args_schema=AddReceivedArgs,\n",
                        "    usr_args_schema=AddUserArgs,\n",
                        "    inp_prompt=add_inp_prompt,\n",
                        "    out_schema=AddResponse,\n",
                        "    set_state_strategy=\"reset\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@add_agent.format_inp_args_handler\n",
                        "def format_inp_args(usr_args: AddUserArgs, rcv_args: AddReceivedArgs, ctx):\n",
                        "    return {\"a\": rcv_args.a, \"b\": usr_args.b}\n",
                        "\n",
                        "\n",
                        "@add_agent.parse_output_handler\n",
                        "def output_handler(conversation, rcv_args, ctx) -> AddResponse:\n",
                        "    return AddResponse(result=int(conversation[-1].content))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "75c68936",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class MultiplyUserArgs(LLMPromptArgs):\n",
                        "    c: int\n",
                        "\n",
                        "\n",
                        "class MultiplyResponse(AgentPayload):\n",
                        "    result: int\n",
                        "\n",
                        "\n",
                        "multiply_inp_prompt = (\n",
                        "    \"Multiply {inp} and {c}. Your only output is the resulting number.\"\n",
                        ")\n",
                        "\n",
                        "multiply_agent = LLMAgent[AddResponse, MultiplyResponse, None](\n",
                        "    agent_id=\"multiply_agent\",\n",
                        "    llm=OpenAILLM(model_name=\"gpt-4.1\", llm_settings=OpenAILLMSettings()),\n",
                        "    rcv_args_schema=AddResponse,\n",
                        "    usr_args_schema=MultiplyUserArgs,\n",
                        "    inp_prompt=multiply_inp_prompt,\n",
                        "    out_schema=MultiplyResponse,\n",
                        "    set_state_strategy=\"reset\",\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@multiply_agent.format_inp_args_handler\n",
                        "def format_inp_args(\n",
                        "    usr_args: MultiplyUserArgs, rcv_args: AddResponse, ctx\n",
                        ") -> dict[str, str]:\n",
                        "    # Combine the output of the add agent with the user input for multiplication\n",
                        "    return {\"inp\": rcv_args.result, \"c\": usr_args.c}\n",
                        "\n",
                        "\n",
                        "@multiply_agent.parse_output_handler\n",
                        "def output_handler(conversation, rcv_args, ctx) -> MultiplyResponse:\n",
                        "    return MultiplyResponse(result=int(conversation[-1].content))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "72f58f89",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_agent = SequentialWorkflowAgent[AddUserArgs, MultiplyResponse, None](\n",
                        "    subagents=[add_agent, multiply_agent],\n",
                        "    agent_id=\"seq_agent\",\n",
                        "    out_schema=MultiplyResponse,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "aeae20e3",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "# Can use batches of inputs here as well\n",
                        "add_run_args = RunArgs(usr=AddUserArgs(b=3))\n",
                        "multiply_run_args = RunArgs(usr=MultiplyUserArgs(c=5))"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "23d1e427",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContextWrapper(\n",
                        "    run_args={\"add_agent\": add_run_args, \"multiply_agent\": multiply_run_args},\n",
                        "    print_messages=True,\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "c1ffbcdc",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "rcv_message = AgentMessage(payloads=[AddReceivedArgs(a=2)], sender_id=\"user\")"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "bec285cb",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "out = await seq_agent.run(rcv_message=rcv_message, ctx=ctx)\n",
                        "print(out.payloads[0].result)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "dbf3874c",
                  "metadata": {},
                  "source": [
                        "# Agents as tools"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "457c5961",
                  "metadata": {},
                  "source": [
                        "When used as tools, the tool inputs are rcv_args"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "aab91548",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_tool = seq_agent.as_tool(\n",
                        "    tool_name=\"seq_agent_tool\",\n",
                        "    tool_description=(\n",
                        "        \"A sequential agent that adds 3 to a given integer, \"\n",
                        "        \"then multiplies the result by 5.\",\n",
                        "    ),\n",
                        ")"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "802b16b4",
                  "metadata": {},
                  "source": [
                        "Description of rcv_args is preserved"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "bd34c0c6",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "seq_tool.in_schema.model_json_schema()"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "55d19e9a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "await seq_tool(a=15, ctx=ctx)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d6fac18e",
                  "metadata": {},
                  "source": [
                        "# Teacher / students"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "65300db8",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "def extract_recipients(message: str) -> list[str]:\n",
                        "    # Find the substring that matches the pattern inside brackets with angle brackets\n",
                        "    match = re.search(r\"\\[(.*?)\\]\", message)\n",
                        "\n",
                        "    if match:\n",
                        "        # Extract the contents inside square brackets\n",
                        "        content = match.group(1)\n",
                        "\n",
                        "        # Extract each student name within angle brackets\n",
                        "        students = re.findall(r\"<(.*?)>\", content)\n",
                        "\n",
                        "        return students  # Output: ['Alice', 'Bob', 'Charlie']\n",
                        "    return []"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "bbc33be8",
                  "metadata": {},
                  "source": [
                        "#### Communication schemas"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "0c9e4401",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "class TeacherExplanation(AgentPayload):\n",
                        "    explanation: str\n",
                        "\n",
                        "\n",
                        "class StudentQuestion(AgentPayload):\n",
                        "    question: str"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "c130874a",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "pool = AgentMessagePool()"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "822a8173",
                  "metadata": {},
                  "source": [
                        "#### Teacher"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "bee8529b",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "teacher_sys_prompt = \"\"\"\n",
                        "You are a teacher explaining quantum gravity to a 2-year old baby (named student1) and a 30-year old graphic designer (named student2). \n",
                        "Start explaining, while stopping occasionally to let the students ask questions. \n",
                        "At the very end of every message, you must specify the recipients of your message \n",
                        "as a list of selected student names with each name in angle brackets, for example: [<Alice>, <Bob>]. \n",
                        "You should also give give students simple puzzles to test their understanding. \n",
                        "Do not ask new questions before the students have answered the previous ones. \n",
                        "When you make sure that the students have understood the topic, you MUST say exactly \"Goodbye, students!\" and terminate the conversation.\n",
                        "\"\"\"\n",
                        "\n",
                        "teacher = LLMAgent[StudentQuestion, TeacherExplanation, None](\n",
                        "    agent_id=\"teacher\",\n",
                        "    llm=OpenAILLM(\n",
                        "        model_name=\"gpt-4o\",\n",
                        "        llm_settings=OpenAILLMSettings(),\n",
                        "    ),\n",
                        "    sys_prompt=teacher_sys_prompt,\n",
                        "    rcv_args_schema=StudentQuestion,\n",
                        "    out_schema=TeacherExplanation,\n",
                        "    message_pool=pool,\n",
                        "    recipient_ids=[\"student1\", \"student2\"],\n",
                        "    set_state_strategy=\"keep\",\n",
                        "    dynamic_routing=True,\n",
                        ")\n",
                        "\n",
                        "\n",
                        "@teacher.parse_output_handler\n",
                        "def teacher_output_handler(conversation, rcv_args, ctx) -> TeacherExplanation:\n",
                        "    message = conversation[-1].content\n",
                        "    recipients = extract_recipients(message)\n",
                        "    explanation = message.split(\"[\")[0].strip()\n",
                        "\n",
                        "    return TeacherExplanation(\n",
                        "        explanation=explanation, selected_recipient_ids=recipients\n",
                        "    )\n",
                        "\n",
                        "\n",
                        "@teacher.exit_handler\n",
                        "def teacher_exit_handler(\n",
                        "    teacher_out: AgentMessage, ctx: RunContextWrapper | None = None\n",
                        ") -> None:\n",
                        "    message = teacher_out.payloads[0].explanation\n",
                        "    return re.search(r\"Goodbye, students!\", message)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "ecec5a2c",
                  "metadata": {},
                  "source": [
                        "#### Students"
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "63797b5d",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "student_sys_prompts = [\n",
                        "    \"\"\"\n",
                        "You are a 2-year old baby trying to make sense of physics. \n",
                        "Your name is <student1>.\n",
                        "There is also another student in the class, a 30 year old graphic designer. \n",
                        "You talk to the teacher only.\n",
                        "\"\"\",\n",
                        "    \"\"\"\n",
                        "You are a 30-year old experienced graphic designer curious about physics. \n",
                        "Your name is <student2>.\n",
                        "Ask questions to the teacher until you understand the topic fully. \n",
                        "Attempt to answer the teacher's questions, but if you don't understand,\n",
                        "ask for clarification. \n",
                        "There is also another student in the class, a 2 year old baby.\n",
                        "\"\"\",\n",
                        "]\n",
                        "\n",
                        "\n",
                        "def make_student_agent(name: str, sys_prompt: str):\n",
                        "    return LLMAgent[TeacherExplanation, StudentQuestion, None](\n",
                        "        agent_id=name,\n",
                        "        llm=OpenAILLM(\n",
                        "            model_name=\"gpt-4o\",\n",
                        "            llm_settings=OpenAILLMSettings(),\n",
                        "        ),\n",
                        "        sys_prompt=sys_prompt,\n",
                        "        rcv_args_schema=TeacherExplanation,\n",
                        "        out_schema=StudentQuestion,\n",
                        "        message_pool=pool,\n",
                        "        recipient_ids=[\"teacher\"],\n",
                        "        set_state_strategy=\"keep\",\n",
                        "        dynamic_routing=False,\n",
                        "    )\n",
                        "\n",
                        "\n",
                        "student1 = make_student_agent(\"student1\", student_sys_prompts[0])\n",
                        "student2 = make_student_agent(\"student2\", student_sys_prompts[1])\n",
                        "\n",
                        "\n",
                        "@student1.parse_output_handler\n",
                        "def student1_output_handler(conversation, rcv_args, ctx) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student1>: \" + conversation[-1].content)\n",
                        "\n",
                        "\n",
                        "@student2.parse_output_handler\n",
                        "def student2_output_handler(conversation, rcv_args, ctx) -> StudentQuestion:\n",
                        "    return StudentQuestion(question=\"<student2>: \" + conversation[-1].content)"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "05add7f7",
                  "metadata": {},
                  "source": [
                        "#### Specify context to be shared across "
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "29623670",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "ctx = RunContextWrapper(print_messages=True)\n",
                        "ctx.printer.color_by = \"agent_id\""
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "d2ffa3fa",
                  "metadata": {},
                  "source": [
                        "#### Run"
                  ]
            },
            {
                  "cell_type": "markdown",
                  "id": "8f5260de",
                  "metadata": {},
                  "source": [
                        "Wait until completion. \n",
                        "\n",
                        "There might be some message pool exceptions at the end that don't affect the functionality."
                  ]
            },
            {
                  "cell_type": "code",
                  "execution_count": null,
                  "id": "77ed257e",
                  "metadata": {},
                  "outputs": [],
                  "source": [
                        "await teacher.start_listening(ctx=ctx)\n",
                        "await student1.start_listening(ctx=ctx)\n",
                        "await student2.start_listening(ctx=ctx)\n",
                        "await teacher.run_and_post(ctx=ctx)"
                  ]
            }
      ],
      "metadata": {
            "kernelspec": {
                  "display_name": ".venv",
                  "language": "python",
                  "name": "python3"
            },
            "language_info": {
                  "codemirror_mode": {
                        "name": "ipython",
                        "version": 3
                  },
                  "file_extension": ".py",
                  "mimetype": "text/x-python",
                  "name": "python",
                  "nbconvert_exporter": "python",
                  "pygments_lexer": "ipython3",
                  "version": "3.11.9"
            }
      },
      "nbformat": 4,
      "nbformat_minor": 5
}
